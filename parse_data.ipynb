{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test, U-test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import project_list, round_number, seed_list, mutant_choice, test_choice\n",
    "TIMED_OUT = 'TIMED_OUT'\n",
    "random_mutant = True\n",
    "random_test = False\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='Precision loss occurred in moment calculation.')\n",
    "\n",
    "\n",
    "def get_mutant_runtimeList_dict(seed):\n",
    "    temp_df = pd.read_csv(f'analyzed-data/{choice}/{seed}_{project}.csv')\n",
    "    temp_dict = {}\n",
    "    for index, row in temp_df.iterrows():\n",
    "        temp_dict[row['mutant']] = [row[f'round-{cnt}'] for cnt in range(round_number)]\n",
    "    return temp_dict\n",
    "\n",
    "\n",
    "def handle_timedOut_noise(array):\n",
    "    if all(x == TIMED_OUT for x in array) or any(x is np.nan for x in array):\n",
    "        return False\n",
    "    fill_value = np.mean([float(x) for x in array if x != TIMED_OUT])\n",
    "    temp_array = []\n",
    "    for x in array:\n",
    "        if x == TIMED_OUT:\n",
    "            temp_array.append(fill_value)\n",
    "        else:\n",
    "            temp_array.append(float(x))\n",
    "    return temp_array\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    for i in range(seed_num):\n",
    "        seed_i = seed_list[i]\n",
    "        i_dict = get_mutant_runtimeList_dict(seed_i)\n",
    "        j = i + 1\n",
    "        while j < seed_num:\n",
    "            df = pd.DataFrame(None, columns=['mutant', 'T-test', 'U-test'])\n",
    "            seed_j = seed_list[j]\n",
    "            j_dict = get_mutant_runtimeList_dict(seed_j)\n",
    "            pair = (seed_i, seed_j)\n",
    "            for mutant, i_runtime_list in i_dict.items():\n",
    "                if not mutant in j_dict:\n",
    "                    continue\n",
    "                j_runtime_list = j_dict[mutant]\n",
    "                i_array = handle_timedOut_noise(i_runtime_list)\n",
    "                j_array = handle_timedOut_noise(j_runtime_list)\n",
    "                if not i_array or not j_array:\n",
    "                    continue\n",
    "                t_stat, t_p_value = ttest_ind(i_array, j_array)\n",
    "                u_stat, u_p_value = mannwhitneyu(i_array, j_array)\n",
    "                df.loc[len(df.index)] = [mutant, t_p_value, u_p_value]\n",
    "            df.to_csv(f'analyzed-data/{choice}/{seed_i}_{seed_j}_{project}.csv', sep=',', header=True, index=False)\n",
    "            j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse T-test/U-test results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pitest_log_parser import project_list, round_number, seed_list, mutant_choice, test_choice\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "for project in project_list:\n",
    "    p_value_record_df = pd.DataFrame(None, columns=['seed-pair', 'mutant', 'T-test', 'U-test'])\n",
    "    for i in range(seed_num):\n",
    "        seed_i = seed_list[i]\n",
    "        j = i + 1\n",
    "        while j < seed_num:\n",
    "            seed_j = seed_list[j]\n",
    "            pair = (seed_i, seed_j)\n",
    "            total_cnt = 0\n",
    "            significance_cnt = 0\n",
    "            df = pd.read_csv(f'analyzed-data/{choice}/{seed_i}_{seed_j}_{project}.csv')\n",
    "            for index, row in df.iterrows():\n",
    "                total_cnt += 1\n",
    "                t_test = float(row['T-test'])\n",
    "                u_test = float(row['U-test'])\n",
    "                if t_test < 0.05 or u_test < 0.05:\n",
    "                    significance_cnt += 1\n",
    "                    p_value_record_df.loc[len(p_value_record_df.index)] = [pair, row['mutant'], t_test, u_test]\n",
    "            j += 1\n",
    "            print(f'{project}-({seed_i}, {seed_j}): {significance_cnt}/{total_cnt}')\n",
    "    p_value_record_df.to_csv(f'analyzed-data/{choice}/significance-record_{project}.csv', sep=',', header=True, index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out falky test.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pitest_log_parser import project_list, round_number, seed_list, mutant_choice, test_choice\n",
    "random_mutant = True\n",
    "random_test = False\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "for project in project_list:\n",
    "    for seed in seed_list:\n",
    "        df = pd.read_csv(f'analyzed-data/{choice}/{seed}_{project}.csv')\n",
    "        withoutTestSet_numberOfMutant_dict = {}\n",
    "        withoutTestSet_testSet_dict = {}\n",
    "        for index, row in df.iterrows():\n",
    "            mutant = eval(row['mutant'])\n",
    "            key = mutant[:-1]\n",
    "            if random_test:\n",
    "                if key in withoutTestSet_numberOfMutant_dict:\n",
    "                    withoutTestSet_numberOfMutant_dict[key] += 1\n",
    "                else:\n",
    "                    withoutTestSet_numberOfMutant_dict[key] = 1\n",
    "            else:\n",
    "                test_set = tuple(set(mutant[-1]))\n",
    "                if key in withoutTestSet_testSet_dict:\n",
    "                    if test_set in withoutTestSet_testSet_dict[key]:\n",
    "                        continue\n",
    "                    withoutTestSet_testSet_dict[key].add(test_set)\n",
    "                    withoutTestSet_numberOfMutant_dict[key] += 1\n",
    "                else:\n",
    "                    withoutTestSet_testSet_dict[key] = {test_set}\n",
    "                    withoutTestSet_numberOfMutant_dict[key] = 1\n",
    "        flakiness_df = pd.DataFrame(None, columns=['mutant-withoutTestSet', 'numberOfMutant'])\n",
    "        for key, value in withoutTestSet_numberOfMutant_dict.items():\n",
    "            flakiness_df.loc[len(flakiness_df.index)] = [key, value]\n",
    "        flakiness_df_sorted = flakiness_df.sort_values(by='numberOfMutant', ascending=False)\n",
    "        flakiness_df_sorted.to_csv(f'analyzed-data/{choice}/flakiness-record_{seed}_{project}', sep=',', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
