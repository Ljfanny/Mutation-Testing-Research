{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = [\n",
    "    'commons-codec',\n",
    "    # 'commons-net',\n",
    "    # 'delight-nashorn-sandbox',\n",
    "    # 'empire-db',\n",
    "    # 'jimfs'\n",
    "]\n",
    "round_number = 6\n",
    "seed_list = [\n",
    "    0,\n",
    "    2024,\n",
    "    99999\n",
    "]\n",
    "parsed_path = 'controlled_parsed_data'\n",
    "analyzed_path = 'controlled_analyzed_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Find out Flaky Mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commons-codec: 3551\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "\n",
    "def get_info(project, seed):\n",
    "    path = f'{parsed_path}/{choice}/{project}_{seed}'\n",
    "    with open(f'{path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    pref_set = set()\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(project, seed)\n",
    "        per_set = set()\n",
    "        for mutant_id, runtime_list in mutantId_runtimeList_dict.items():\n",
    "            if any(np.isnan(runtime) for runtime in runtime_list if isinstance(runtime, float)):\n",
    "                continue\n",
    "            per_set.add(tuple(mutantId_mutantTuple_dict[mutant_id][:5]))\n",
    "        if len(pref_set) == 0:\n",
    "            pref_set |= per_set\n",
    "        else:\n",
    "            pref_set &= per_set\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(project, seed)\n",
    "        non_flaky_list = []\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            if tuple(mutant_tuple[:5]) in pref_set:\n",
    "                non_flaky_list.append(mutant_id)\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'w') as file:\n",
    "            json.dump(non_flaky_list, file, indent=4)\n",
    "    print(f'{project}: {len(non_flaky_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Calculate T-test, U-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commons-codec with (0, 2024): 764/3551\n",
      "commons-codec with (0, 99999): 3003/3551\n",
      "commons-codec with (2024, 99999): 2623/3551\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='Precision loss occurred in moment calculation.')\n",
    "\n",
    "\n",
    "def get_info(project, seed):\n",
    "    path = f'{parsed_path}/{choice}/{project}_{seed}'\n",
    "    with open(f'{path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "def to_be_calculable(runtime_list):\n",
    "    output_list = []\n",
    "    for runtime in runtime_list:\n",
    "        if runtime == TIMED_OUT:\n",
    "            output_list.append(6000)\n",
    "        else:\n",
    "            output_list.append(runtime)\n",
    "    return output_list\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    seed_mutants_dict = {}\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(project, seed)\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        seed_mutants_dict[seed] = {}\n",
    "        for mutant_id in non_flaky_list:\n",
    "            mutant_pref = tuple(mutantId_mutantTuple_dict[mutant_id][:5])\n",
    "            seed_mutants_dict[seed][mutant_pref] = to_be_calculable(mutantId_runtimeList_dict[mutant_id])\n",
    "    for i in range(seed_num):\n",
    "        i_seed = seed_list[i]\n",
    "        i_mutants_dict = seed_mutants_dict[i_seed]\n",
    "        j = i + 1\n",
    "        while j < seed_num:\n",
    "            df = pd.DataFrame(None, columns=['mutant', 'T-test', 'U-test'])\n",
    "            j_seed = seed_list[j]\n",
    "            j_mutants_dict = seed_mutants_dict[j_seed]\n",
    "            significant_number = 0\n",
    "            for pref, i_runtime_list in i_mutants_dict.items():\n",
    "                j_runtime_list = j_mutants_dict[pref]\n",
    "                t_stat, t_p_value = ttest_ind(i_runtime_list, j_runtime_list)\n",
    "                u_stat, u_p_value = mannwhitneyu(i_runtime_list, j_runtime_list)\n",
    "                if t_p_value < 0.05 or u_p_value < 0.05:\n",
    "                    significant_number += 1\n",
    "                df.loc[len(df.index)] = [pref, t_p_value, u_p_value]\n",
    "            df.to_csv(f'{analyzed_path}/{choice}/significance_detection/non-flaky/{project}_{i_seed}_{j_seed}.csv', sep=',', header=True, index=False)\n",
    "            j += 1\n",
    "            print(f'{project} with ({i_seed}, {j_seed}): {significant_number}/{len(non_flaky_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get total running time except flaky mutants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "def add_list(array1, array2):\n",
    "    for i in range(round_number):\n",
    "        if array2[i] == TIMED_OUT:\n",
    "            array1[i] += 6000\n",
    "        else:\n",
    "            array1[i] += int(array2[i])\n",
    "\n",
    "\n",
    "up_dir = f'{analyzed_path}/{choice}/total_running_time/non-flaky'\n",
    "significant_df = pd.DataFrame(None, columns=['project', 'seed-pair', 'T-test', 'U-test'])\n",
    "columns = ['seed'] + [f'round-{i}' for i in range(round_number)]\n",
    "for project in project_list:\n",
    "    df = pd.DataFrame(None, columns=columns)\n",
    "    seed_totalRuntimeList_dict = {}\n",
    "    for seed in seed_list:\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        runtime_list = [0 for _ in range(round_number)]\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mutant_id in non_flaky_list:\n",
    "            add_list(runtime_list, mutantId_runtimeList_dict[mutant_id])\n",
    "        seed_totalRuntimeList_dict[seed] = runtime_list\n",
    "        df.loc[len(df.index)] = [seed] + runtime_list\n",
    "    for i in range(seed_num):\n",
    "        i_seed = seed_list[i]\n",
    "        i_array = seed_totalRuntimeList_dict[i_seed]\n",
    "        for j in range(seed_num):\n",
    "            if j > i:\n",
    "                j_seed = seed_list[j]\n",
    "                j_array = seed_totalRuntimeList_dict[j_seed]\n",
    "                t_stat, t_p_value = ttest_ind(i_array, j_array)\n",
    "                u_stat, u_p_value = mannwhitneyu(i_array, j_array)\n",
    "                significant_df.loc[len(significant_df.index)] = [project, (i_seed, j_seed), t_p_value, u_p_value]\n",
    "    df.to_csv(f'{up_dir}/{project}.csv', sep=',', header=True, index=False)\n",
    "significant_df.to_csv(f'{up_dir}/significant_results.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with fastest\n",
    "import pandas as pd\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "def add_list(array1, array2):\n",
    "    for i in range(round_number):\n",
    "        if array2[i] == TIMED_OUT:\n",
    "            array1[i] += 6000\n",
    "        else:\n",
    "            array1[i] += int(array2[i])\n",
    "\n",
    "\n",
    "up_dir = f'{analyzed_path}/{choice}/total_running_time/non-flaky'\n",
    "significant_df = pd.DataFrame(None, columns=['project', 'seed-pair', 'T-test', 'U-test'])\n",
    "columns = ['seed'] + [f'round-{i}' for i in range(round_number)]\n",
    "for project in project_list:\n",
    "    df = pd.DataFrame(None, columns=columns)\n",
    "    seed_totalRuntimeList_dict = {}\n",
    "    for seed in seed_list:\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        runtime_list = [0 for _ in range(round_number)]\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mutant_id in non_flaky_list:\n",
    "            add_list(runtime_list, mutantId_runtimeList_dict[mutant_id])\n",
    "        seed_totalRuntimeList_dict[seed] = runtime_list\n",
    "        df.loc[len(df.index)] = [seed] + runtime_list\n",
    "    # fastest one\n",
    "    _, mutantId_runtimeList_dict = get_info(f'{parsed_path}/{choice}/{project}_fastest')\n",
    "    fastest_array = [0 for _ in range(round_number)]\n",
    "    for _, runtime_list in mutantId_runtimeList_dict.items():\n",
    "        add_list(fastest_array, runtime_list)\n",
    "    for seed in seed_list:\n",
    "        array = seed_totalRuntimeList_dict[seed]\n",
    "        t_stat, t_p_value = ttest_ind(array, fastest_array)\n",
    "        u_stat, u_p_value = mannwhitneyu(array, fastest_array)\n",
    "        significant_df.loc[len(significant_df.index)] = [project, (seed, 'fastest'), t_p_value, u_p_value]  \n",
    "    df.to_csv(f'{up_dir}/{project}_VS_fastest.csv', sep=',', header=True, index=False)\n",
    "significant_df.to_csv(f'{up_dir}/significant_results_VS_fastest.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commons-codec with 0:\n",
      "Total mutants: 3559\n",
      "Non-flaky mutants: 3559 (1.0000)\n",
      "Flaky mutants due to chaotic test list: 0 (0.0000)\n",
      "commons-codec with 2024:\n",
      "Total mutants: 3556\n",
      "Non-flaky mutants: 3556 (1.0000)\n",
      "Flaky mutants due to chaotic test list: 0 (0.0000)\n",
      "commons-codec with 99999:\n",
      "Total mutants: 3556\n",
      "Non-flaky mutants: 3556 (1.0000)\n",
      "Flaky mutants due to chaotic test list: 0 (0.0000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    total_flaky_tests = set()\n",
    "    for seed in seed_list:\n",
    "        flaky_chaotic_order_mutant_list = []\n",
    "        total_num = 0\n",
    "        non_flaky_num = 0\n",
    "        flaky_chaotic_order_num = 0\n",
    "        uniqueId_mutantIds_dict = {}\n",
    "        mutantId_mutantTuple_dict, mutantId_testsInOrder_dict, mutantId_runtimeList_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            unique_id = tuple(mutant_tuple[:5])\n",
    "            test_list = mutantId_testsInOrder_dict[mutant_id]\n",
    "            if unique_id not in uniqueId_mutantIds_dict:\n",
    "                uniqueId_mutantIds_dict[unique_id] = set()\n",
    "            uniqueId_mutantIds_dict[unique_id].add(mutant_id)\n",
    "        total_num = len(uniqueId_mutantIds_dict)\n",
    "        for unique_id, mutant_ids in uniqueId_mutantIds_dict.items():\n",
    "            if len(mutant_ids) == 1:\n",
    "                non_flaky_num += 1\n",
    "            else:\n",
    "                test_intersection_set = None\n",
    "                for mutant_id in mutant_ids:\n",
    "                    per_test_set = set(mutantId_testsInOrder_dict[mutant_id])\n",
    "                    if test_intersection_set is None:\n",
    "                        test_intersection_set = per_test_set\n",
    "                    else:\n",
    "                        test_intersection_set &= per_test_set\n",
    "                is_same = True\n",
    "                flaky_tests = set()\n",
    "                for mutant_id in mutant_ids:\n",
    "                    per_test_set = set(mutantId_testsInOrder_dict[mutant_id])\n",
    "                    if len(per_test_set) == len(test_intersection_set):\n",
    "                        continue\n",
    "                    flaky_tests |= (per_test_set - test_intersection_set)\n",
    "                if len(flaky_tests) == 0:\n",
    "                    flaky_chaotic_order_num += 1\n",
    "                    flaky_chaotic_order_mutant_list.append(random.choice(list(mutant_ids)))\n",
    "                total_flaky_tests |= flaky_tests\n",
    "        # with open(f'analyzed_data/{choice}/mutant_list/chaotic_order/{project}_{seed}.json', 'w') as file:\n",
    "        #     json.dump(flaky_chaotic_order_mutant_list, file, indent=4)\n",
    "    \n",
    "        print(f'{project} with {seed}:')\n",
    "        print(f'Total mutants: {total_num}')\n",
    "        print(f'Non-flaky mutants: {non_flaky_num} ({non_flaky_num / total_num:.4f})')\n",
    "        print(f'Flaky mutants due to chaotic test list: {flaky_chaotic_order_num} ({flaky_chaotic_order_num / total_num:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create guiding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict, mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    def test_sort(test):\n",
    "        return (test['name'])\n",
    "    \n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    if random_test:\n",
    "        random.shuffle(test_order)\n",
    "    else:\n",
    "        test_order.sort(key=test_sort)\n",
    "\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'filename': mutant[5],\n",
    "        'block': f'[{mutant[6]}]',\n",
    "        'lineNumber': int(mutant[7]),\n",
    "        'description': mutant[8],\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "\n",
    "\n",
    "parent_path = f'analyzed_data/{choice}/mutant_list'\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    # get the mutant intersection\n",
    "    id_set = set()\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, _ = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        with open(f'{parent_path}/chaotic_order/{project}_{seed}.json', 'r') as file:\n",
    "            chaotic_order_list = json.load(file)\n",
    "        per_id_set = set()\n",
    "        for mutant_id in chaotic_order_list:\n",
    "            per_id_set.add(tuple(mutantId_mutantTuple_dict[mutant_id][:5]))\n",
    "        if len(id_set) == 0:\n",
    "            id_set |= per_id_set\n",
    "        else:\n",
    "            id_set &= per_id_set\n",
    "    # create guiding mutant list\n",
    "    for seed in seed_list:\n",
    "        with open(f'{parent_path}/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        mutantId_mutantTuple_dict, mutantId_testsInOrder_dict = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        output_list = []\n",
    "        id_visited_dict = {item: True for item in id_set}\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            id_tuple = tuple(mutant_tuple[:5])\n",
    "            if mutant_id in non_flaky_list or (id_tuple in id_set and id_visited_dict[id_tuple]):\n",
    "                if id_tuple in id_set:\n",
    "                    id_visited_dict[id_tuple] = False\n",
    "                output_list.append(mutant_to_json(mutant=mutant_tuple,\n",
    "                                                  test_list=mutantId_testsInOrder_dict[mutant_id],\n",
    "                                                  junit_version=junit_version))\n",
    "        if random_mutant:\n",
    "            random.shuffle(output_list)\n",
    "        else:\n",
    "            output_list.sort(key=mutant_sort)\n",
    "        with open(f'analyzed_data/{choice}/guiding_file/{project}_{seed}.json', 'w') as f:\n",
    "            f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Choose fastest test order to guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict, mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict, mutantId_testsInOrder_dict\n",
    "\n",
    "\n",
    "def to_be_calculable(runtime):\n",
    "    if runtime == TIMED_OUT:\n",
    "        return 6000\n",
    "    else:\n",
    "        return int(runtime)\n",
    "    \n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "    \n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    def test_sort(test):\n",
    "        return (test['name'])\n",
    "    \n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    if random_test:\n",
    "        random.shuffle(test_order)\n",
    "    else:\n",
    "        test_order.sort(key=test_sort)\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'filename': mutant[5],\n",
    "        'block': f'[{mutant[6]}]',\n",
    "        'lineNumber': int(mutant[7]),\n",
    "        'description': mutant[8],\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    mutation_runtime_dict = {}\n",
    "    mutation_tests_dict = {}\n",
    "    is_visited = False\n",
    "    for seed in seed_list:\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict, mutantId_testsInOrder_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mutant_id in non_flaky_list:\n",
    "            mutant = tuple(mutantId_mutantTuple_dict[mutant_id])\n",
    "            new_runtime = sum([to_be_calculable(runtime) for runtime in mutantId_runtimeList_dict[mutant_id]])\n",
    "            if not is_visited:\n",
    "                mutation_tests_dict[mutant] = mutantId_testsInOrder_dict[mutant_id]\n",
    "                mutation_runtime_dict[mutant] = new_runtime\n",
    "            else:\n",
    "                if new_runtime < mutation_runtime_dict[mutant]:\n",
    "                    mutation_tests_dict[mutant] = mutantId_testsInOrder_dict[mutant_id]\n",
    "                    mutation_runtime_dict[mutant] = new_runtime\n",
    "        is_visited = True\n",
    "    output_list = []\n",
    "    for mutant, testsInOrder in mutation_tests_dict.items():\n",
    "        output_list.append(mutant_to_json(\n",
    "            mutant=mutant,\n",
    "            test_list=testsInOrder,\n",
    "            junit_version=junit_version\n",
    "        ))\n",
    "    output_list.sort(key=mutant_sort)\n",
    "    with open(f'{analyzed_path}/{choice}/guiding_file/{project}.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
