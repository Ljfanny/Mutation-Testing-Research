{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = [\n",
    "    'commons-codec',\n",
    "    # 'commons-net',\n",
    "    'delight-nashorn-sandbox',\n",
    "    'empire-db',\n",
    "    'jimfs'\n",
    "]\n",
    "round_number = 6\n",
    "seed_list = [\n",
    "    0,\n",
    "    2024,\n",
    "    99999\n",
    "]\n",
    "parsed_path = 'controlled_parsed_data'\n",
    "analyzed_path = 'controlled_analyzed_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Find out Flaky Mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "\n",
    "def get_info(project, seed):\n",
    "    path = f'{parsed_path}/{choice}/{project}_{seed}'\n",
    "    with open(f'{path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    pref_set = set()\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(project, seed)\n",
    "        per_set = set()\n",
    "        for mutant_id, runtime_list in mutantId_runtimeList_dict.items():\n",
    "            if any(np.isnan(runtime) for runtime in runtime_list if isinstance(runtime, float)):\n",
    "                continue\n",
    "            per_set.add(tuple(mutantId_mutantTuple_dict[mutant_id][:5]))\n",
    "        if len(pref_set) == 0:\n",
    "            pref_set |= per_set\n",
    "        else:\n",
    "            pref_set &= per_set\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(project, seed)\n",
    "        non_flaky_list = []\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            if tuple(mutant_tuple[:5]) in pref_set:\n",
    "                non_flaky_list.append(mutant_id)\n",
    "        # with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'w') as file:\n",
    "        #     json.dump(non_flaky_list, file, indent=4)\n",
    "    print(f'{project}: {len(non_flaky_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Calculate T-test, U-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='Precision loss occurred in moment calculation.')\n",
    "\n",
    "\n",
    "def get_info(project, seed):\n",
    "    path = f'{parsed_path}/{choice}/{project}_{seed}'\n",
    "    with open(f'{path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "def to_be_calculable(runtime_list):\n",
    "    output_list = []\n",
    "    for runtime in runtime_list:\n",
    "        if runtime == TIMED_OUT:\n",
    "            output_list.append(6000)\n",
    "        else:\n",
    "            output_list.append(runtime)\n",
    "    return output_list\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    seed_mutants_dict = {}\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(project, seed)\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        seed_mutants_dict[seed] = {}\n",
    "        for mutant_id in non_flaky_list:\n",
    "            mutant_pref = tuple(mutantId_mutantTuple_dict[mutant_id][:5])\n",
    "            seed_mutants_dict[seed][mutant_pref] = to_be_calculable(mutantId_runtimeList_dict[mutant_id])\n",
    "    for i in range(seed_num):\n",
    "        i_seed = seed_list[i]\n",
    "        i_mutants_dict = seed_mutants_dict[i_seed]\n",
    "        j = i + 1\n",
    "        while j < seed_num:\n",
    "            df = pd.DataFrame(None, columns=['mutant', 'T-test', 'U-test'])\n",
    "            j_seed = seed_list[j]\n",
    "            j_mutants_dict = seed_mutants_dict[j_seed]\n",
    "            significant_number = 0\n",
    "            for pref, i_runtime_list in i_mutants_dict.items():\n",
    "                j_runtime_list = j_mutants_dict[pref]\n",
    "                t_stat, t_p_value = ttest_ind(i_runtime_list, j_runtime_list)\n",
    "                u_stat, u_p_value = mannwhitneyu(i_runtime_list, j_runtime_list)\n",
    "                if t_p_value < 0.05 or u_p_value < 0.05:\n",
    "                    significant_number += 1\n",
    "                df.loc[len(df.index)] = [pref, t_p_value, u_p_value]\n",
    "            # df.to_csv(f'{analyzed_path}/{choice}/significance_detection/non-flaky/{project}_{i_seed}_{j_seed}.csv', sep=',', header=True, index=False)\n",
    "            j += 1\n",
    "            print(f'{project} with ({i_seed}, {j_seed}): {significant_number}/{len(non_flaky_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get total running time except flaky mutants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "def add_list(array1, array2):\n",
    "    for i in range(round_number):\n",
    "        if array2[i] == TIMED_OUT:\n",
    "            array1[i] += 6000\n",
    "        else:\n",
    "            array1[i] += int(array2[i])\n",
    "\n",
    "\n",
    "up_dir = f'{analyzed_path}/{choice}/total_running_time/non-flaky'\n",
    "significant_df = pd.DataFrame(None, columns=['project', 'seed-pair', 'T-test', 'U-test'])\n",
    "columns = ['seed'] + [f'round-{i}' for i in range(round_number)]\n",
    "for project in project_list:\n",
    "    df = pd.DataFrame(None, columns=columns)\n",
    "    seed_totalRuntimeList_dict = {}\n",
    "    for seed in seed_list:\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        runtime_list = [0 for _ in range(round_number)]\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mutant_id in non_flaky_list:\n",
    "            add_list(runtime_list, mutantId_runtimeList_dict[mutant_id])\n",
    "        seed_totalRuntimeList_dict[seed] = runtime_list\n",
    "        df.loc[len(df.index)] = [seed] + runtime_list\n",
    "    for i in range(seed_num):\n",
    "        i_seed = seed_list[i]\n",
    "        i_array = seed_totalRuntimeList_dict[i_seed]\n",
    "        for j in range(seed_num):\n",
    "            if j > i:\n",
    "                j_seed = seed_list[j]\n",
    "                j_array = seed_totalRuntimeList_dict[j_seed]\n",
    "                t_stat, t_p_value = ttest_ind(i_array, j_array)\n",
    "                u_stat, u_p_value = mannwhitneyu(i_array, j_array)\n",
    "                significant_df.loc[len(significant_df.index)] = [project, (i_seed, j_seed), t_p_value, u_p_value]\n",
    "    df.to_csv(f'{up_dir}/{project}.csv', sep=',', header=True, index=False)\n",
    "significant_df.to_csv(f'{up_dir}/significant_results.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with fastest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "def add_list(array1, array2):\n",
    "    for i in range(round_number):\n",
    "        if array2[i] == TIMED_OUT:\n",
    "            array1[i] += 6000\n",
    "        else:\n",
    "            array1[i] += int(array2[i])\n",
    "\n",
    "\n",
    "up_dir = f'{analyzed_path}/{choice}/total_running_time/non-flaky'\n",
    "significant_df = pd.DataFrame(None, columns=['project', 'seed', 'T-test', 'U-test', 'reduction_percentage'])\n",
    "columns = ['seed'] + [f'round-{i}' for i in range(round_number)]\n",
    "for project in project_list:\n",
    "    seed_totalRuntimeList_dict = {}\n",
    "    for seed in seed_list:\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        runtime_list = [0 for _ in range(round_number)]\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mutant_id in non_flaky_list:\n",
    "            add_list(runtime_list, mutantId_runtimeList_dict[mutant_id])\n",
    "        seed_totalRuntimeList_dict[seed] = runtime_list\n",
    "    # fastest one\n",
    "    _, mutantId_runtimeList_dict = get_info(f'{parsed_path}/{choice}/{project}_fastest')\n",
    "    fastest_array = [0 for _ in range(round_number)]\n",
    "    for _, runtime_list in mutantId_runtimeList_dict.items():\n",
    "        add_list(fastest_array, runtime_list)\n",
    "    for seed in seed_list:\n",
    "        array = seed_totalRuntimeList_dict[seed]\n",
    "        t_stat, t_p_value = ttest_ind(array, fastest_array)\n",
    "        u_stat, u_p_value = mannwhitneyu(array, fastest_array)\n",
    "        avg_rate = np.mean(fastest_array) / np.mean(array)\n",
    "        significant_df.loc[len(significant_df.index)] = [project, seed, f'{t_p_value:.3f}',\n",
    "                                                         f'{u_p_value:.3f}', f'{avg_rate:.3f}']\n",
    "    print(f'{project} with fastest:')\n",
    "    print(fastest_array)\n",
    "significant_df.to_csv(f'{up_dir}/significant_results_VS_fastest.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_num = len(seed_list)\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    total_flaky_tests = set()\n",
    "    for seed in seed_list:\n",
    "        flaky_chaotic_order_mutant_list = []\n",
    "        total_num = 0\n",
    "        non_flaky_num = 0\n",
    "        flaky_chaotic_order_num = 0\n",
    "        uniqueId_mutantIds_dict = {}\n",
    "        mutantId_mutantTuple_dict, mutantId_testsInOrder_dict, mutantId_runtimeList_dict = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            unique_id = tuple(mutant_tuple[:5])\n",
    "            test_list = mutantId_testsInOrder_dict[mutant_id]\n",
    "            if unique_id not in uniqueId_mutantIds_dict:\n",
    "                uniqueId_mutantIds_dict[unique_id] = set()\n",
    "            uniqueId_mutantIds_dict[unique_id].add(mutant_id)\n",
    "        total_num = len(uniqueId_mutantIds_dict)\n",
    "        for unique_id, mutant_ids in uniqueId_mutantIds_dict.items():\n",
    "            if len(mutant_ids) == 1:\n",
    "                non_flaky_num += 1\n",
    "            else:\n",
    "                test_intersection_set = None\n",
    "                for mutant_id in mutant_ids:\n",
    "                    per_test_set = set(mutantId_testsInOrder_dict[mutant_id])\n",
    "                    if test_intersection_set is None:\n",
    "                        test_intersection_set = per_test_set\n",
    "                    else:\n",
    "                        test_intersection_set &= per_test_set\n",
    "                is_same = True\n",
    "                flaky_tests = set()\n",
    "                for mutant_id in mutant_ids:\n",
    "                    per_test_set = set(mutantId_testsInOrder_dict[mutant_id])\n",
    "                    if len(per_test_set) == len(test_intersection_set):\n",
    "                        continue\n",
    "                    flaky_tests |= (per_test_set - test_intersection_set)\n",
    "                if len(flaky_tests) == 0:\n",
    "                    flaky_chaotic_order_num += 1\n",
    "                    flaky_chaotic_order_mutant_list.append(random.choice(list(mutant_ids)))\n",
    "                total_flaky_tests |= flaky_tests\n",
    "        # with open(f'analyzed_data/{choice}/mutant_list/chaotic_order/{project}_{seed}.json', 'w') as file:\n",
    "        #     json.dump(flaky_chaotic_order_mutant_list, file, indent=4)\n",
    "    \n",
    "        print(f'{project} with {seed}:')\n",
    "        print(f'Total mutants: {total_num}')\n",
    "        print(f'Non-flaky mutants: {non_flaky_num} ({non_flaky_num / total_num:.4f})')\n",
    "        print(f'Flaky mutants due to chaotic test list: {flaky_chaotic_order_num} ({flaky_chaotic_order_num / total_num:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create guiding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict, mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    def test_sort(test):\n",
    "        return (test['name'])\n",
    "    \n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    if random_test:\n",
    "        random.shuffle(test_order)\n",
    "    else:\n",
    "        test_order.sort(key=test_sort)\n",
    "\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'filename': mutant[5],\n",
    "        'block': f'[{mutant[6]}]',\n",
    "        'lineNumber': int(mutant[7]),\n",
    "        'description': mutant[8],\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "\n",
    "\n",
    "parent_path = f'analyzed_data/{choice}/mutant_list'\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    # get the mutant intersection\n",
    "    id_set = set()\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, _ = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        with open(f'{parent_path}/chaotic_order/{project}_{seed}.json', 'r') as file:\n",
    "            chaotic_order_list = json.load(file)\n",
    "        per_id_set = set()\n",
    "        for mutant_id in chaotic_order_list:\n",
    "            per_id_set.add(tuple(mutantId_mutantTuple_dict[mutant_id][:5]))\n",
    "        if len(id_set) == 0:\n",
    "            id_set |= per_id_set\n",
    "        else:\n",
    "            id_set &= per_id_set\n",
    "    # create guiding mutant list\n",
    "    for seed in seed_list:\n",
    "        with open(f'{parent_path}/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        mutantId_mutantTuple_dict, mutantId_testsInOrder_dict = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        output_list = []\n",
    "        id_visited_dict = {item: True for item in id_set}\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            id_tuple = tuple(mutant_tuple[:5])\n",
    "            if mutant_id in non_flaky_list or (id_tuple in id_set and id_visited_dict[id_tuple]):\n",
    "                if id_tuple in id_set:\n",
    "                    id_visited_dict[id_tuple] = False\n",
    "                output_list.append(mutant_to_json(mutant=mutant_tuple,\n",
    "                                                  test_list=mutantId_testsInOrder_dict[mutant_id],\n",
    "                                                  junit_version=junit_version))\n",
    "        if random_mutant:\n",
    "            random.shuffle(output_list)\n",
    "        else:\n",
    "            output_list.sort(key=mutant_sort)\n",
    "        with open(f'analyzed_data/{choice}/guiding_files/{project}_{seed}.json', 'w') as f:\n",
    "            f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Choose fastest test order to guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict, mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict, mutantId_testsInOrder_dict\n",
    "\n",
    "\n",
    "def to_be_calculable(runtime):\n",
    "    if runtime == TIMED_OUT:\n",
    "        return 6000\n",
    "    else:\n",
    "        return int(runtime)\n",
    "    \n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "    \n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    def test_sort(test):\n",
    "        return (test['name'])\n",
    "    \n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    if random_test:\n",
    "        random.shuffle(test_order)\n",
    "    else:\n",
    "        test_order.sort(key=test_sort)\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'filename': mutant[5],\n",
    "        'block': f'[{mutant[6]}]',\n",
    "        'lineNumber': int(mutant[7]),\n",
    "        'description': mutant[8],\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    mutation_runtime_dict = {}\n",
    "    mutation_tests_dict = {}\n",
    "    is_visited = False\n",
    "    for seed in seed_list:\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict, mutantId_testsInOrder_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mutant_id in non_flaky_list:\n",
    "            mutant = tuple(mutantId_mutantTuple_dict[mutant_id])\n",
    "            new_runtime = sum([to_be_calculable(runtime) for runtime in mutantId_runtimeList_dict[mutant_id]])\n",
    "            if not is_visited:\n",
    "                mutation_tests_dict[mutant] = mutantId_testsInOrder_dict[mutant_id]\n",
    "                mutation_runtime_dict[mutant] = new_runtime\n",
    "            else:\n",
    "                if new_runtime < mutation_runtime_dict[mutant]:\n",
    "                    mutation_tests_dict[mutant] = mutantId_testsInOrder_dict[mutant_id]\n",
    "                    mutation_runtime_dict[mutant] = new_runtime\n",
    "        is_visited = True\n",
    "    output_list = []\n",
    "    for mutant, testsInOrder in mutation_tests_dict.items():\n",
    "        output_list.append(mutant_to_json(\n",
    "            mutant=mutant,\n",
    "            test_list=testsInOrder,\n",
    "            junit_version=junit_version\n",
    "        ))\n",
    "    output_list.sort(key=mutant_sort)\n",
    "    with open(f'{analyzed_path}/{choice}/guiding_files/{project}.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. About mutation xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commons-codec: 14/3551\n",
      "delight-nashorn-sandbox: 28/225\n",
      "empire-db: 14/2232\n",
      "jimfs: 20/1520\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict, mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "seed_number = len(seed_list)\n",
    "\n",
    "def mutation_filter(mutations, non_flaky_list, mutantId_mutantTuple_dict):\n",
    "    non_flaky_mutations = []\n",
    "    for idx in non_flaky_list:\n",
    "        mutuple = mutantId_mutantTuple_dict[idx]\n",
    "        indexes = None\n",
    "        if ',' in mutuple[3]:\n",
    "            indexes = mutuple[3].split(', ')\n",
    "        else:\n",
    "            indexes = [mutuple[3]]\n",
    "        non_flaky_mutations.append({\n",
    "            'mutatedClass': mutuple[0],\n",
    "            'mutatedMethod': mutuple[1],\n",
    "            'methodDescription': mutuple[2],\n",
    "            'indexes': indexes,\n",
    "            'mutator': mutuple[4]\n",
    "            })\n",
    "    filtered_mutations = []\n",
    "    filtered_indexes = []\n",
    "    keys_to_extract = ['mutatedClass', 'mutatedMethod', 'methodDescription', 'indexes', 'mutator']\n",
    "    for i, mut in enumerate(mutations):\n",
    "        if {k: mut[k] for k in keys_to_extract} in non_flaky_mutations:\n",
    "            filtered_mutations.append(mut)\n",
    "            filtered_indexes.append(i)\n",
    "    return filtered_mutations, filtered_indexes\n",
    "\n",
    "\n",
    "def is_different(tests0, tests1):\n",
    "    if tests0 is None and tests1 is None:\n",
    "        return False\n",
    "    if tests0 is None or tests1 is None:\n",
    "        return True\n",
    "    if set(tests0) == set(tests1):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def test_recorder(test_statuses_dict, i, tests, status):\n",
    "    if tests is None:\n",
    "        return\n",
    "    for t in tests:\n",
    "        if not t in test_statuses_dict:\n",
    "            test_statuses_dict[t] = ['' for _ in range(seed_number)]\n",
    "        if test_statuses_dict[t][i] == '' or test_statuses_dict[t][i] == status:\n",
    "            test_statuses_dict[t][i] = status\n",
    "        else:\n",
    "            test_statuses_dict[t][i] = 'killed/survived'\n",
    "\n",
    "\n",
    "parent_path = f'controlled_parsed_data/{choice}'\n",
    "for project in project_list:\n",
    "    muid_isConsistent_dict = {}\n",
    "    muid_killedTests_dict = {}\n",
    "    muid_succeedingTests_dict = {}\n",
    "    muid_indexMatrix_dict = {}\n",
    "    is_visited = False\n",
    "    for i, seed in enumerate(seed_list):\n",
    "        with open(f'{parent_path}/{project}_{seed}/mutations_xml.json', 'r') as file:\n",
    "            mutation_list = json.load(file)\n",
    "        with open(f'{parent_path}/{project}_{seed}/mutantId_mutantTuple.json', 'r') as file:\n",
    "            mutantId_mutantTuple_dict = json.load(file)\n",
    "        with open(f'controlled_analyzed_data/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        filtered_mutations, filtered_indexes = mutation_filter(mutation_list,\n",
    "                                                               non_flaky_list,\n",
    "                                                               mutantId_mutantTuple_dict)\n",
    "        if not is_visited:\n",
    "            for mutation in filtered_mutations:\n",
    "                muid = (mutation['mutatedClass'], mutation['mutatedMethod'], mutation['methodDescription'])\n",
    "                muid += (str(mutation['indexes']), mutation['mutator'])\n",
    "                muid_isConsistent_dict[muid] = True\n",
    "                muid_indexMatrix_dict[muid] = [[] for _ in range(seed_number)]\n",
    "                muid_killedTests_dict[muid] = mutation['killingTests']\n",
    "                muid_succeedingTests_dict[muid] = mutation['succeedingTests']\n",
    "         \n",
    "        # the same order has different statuses.\n",
    "        for j, mutation in enumerate(filtered_mutations):\n",
    "            muid = (mutation['mutatedClass'], mutation['mutatedMethod'], mutation['methodDescription'])\n",
    "            muid += (str(mutation['indexes']), mutation['mutator'])\n",
    "            if len(muid_indexMatrix_dict[muid][i]) >= 1:\n",
    "                k = muid_indexMatrix_dict[muid][i][0]\n",
    "                if is_different(filtered_mutations[k]['killingTests'], mutation['killingTests']) or is_different(filtered_mutations[k]['succeedingTests'], mutation['succeedingTests']):\n",
    "                    muid_isConsistent_dict[muid] = False\n",
    "            muid_indexMatrix_dict[muid][i] += [filtered_indexes[j]]\n",
    "        \n",
    "        # the different order has different statuses.\n",
    "        if is_visited:\n",
    "            for j, mutation in enumerate(filtered_mutations):\n",
    "                muid = (mutation['mutatedClass'], mutation['mutatedMethod'], mutation['methodDescription'])\n",
    "                muid += (str(mutation['indexes']), mutation['mutator'])\n",
    "                if not muid_isConsistent_dict[muid]:\n",
    "                    continue\n",
    "                killing_tests = mutation['killingTests']\n",
    "                succeeding_tests = mutation['succeedingTests']\n",
    "                if is_different(muid_killedTests_dict[muid], killing_tests) or is_different(muid_succeedingTests_dict[muid], succeeding_tests):\n",
    "                    muid_isConsistent_dict[muid] = False  \n",
    "        is_visited = True\n",
    "    cnt = 0\n",
    "    df = pd.DataFrame(None, columns=['mutated_class', 'mutated_method', 'method_description', 'indexes', 'mutator',\n",
    "                                     'test'] + [f'seed_{s}' for s in seed_list])\n",
    "    for muid, is_consistent in muid_isConsistent_dict.items():\n",
    "        if is_consistent:\n",
    "            continue\n",
    "        cnt += 1\n",
    "        test_statuses_dict = {}\n",
    "        for i, indexes in enumerate(muid_indexMatrix_dict[muid]):\n",
    "            with open(f'{parent_path}/{project}_{seed_list[i]}/mutations_xml.json', 'r') as file:\n",
    "                mutation_list = json.load(file)\n",
    "            for index in indexes:\n",
    "                mutation = mutation_list[index]\n",
    "                test_recorder(test_statuses_dict, i, mutation['killingTests'], 'killed')\n",
    "                test_recorder(test_statuses_dict, i, mutation['succeedingTests'], 'survived')\n",
    "        for i, indexes in enumerate(muid_indexMatrix_dict[muid]):\n",
    "            with open(f'{parent_path}/{project}_{seed_list[i]}/mutations_xml.json', 'r') as file:\n",
    "                mutation_list = json.load(file)    \n",
    "            for index in indexes:\n",
    "                mutation = mutation_list[index]\n",
    "                if mutation['status'] in [TIMED_OUT, 'MEMORY_ERROR']:\n",
    "                    for t, statuses in test_statuses_dict.items():\n",
    "                        if test_statuses_dict[t][i] == '':\n",
    "                            test_statuses_dict[t][i] = mutation['status']\n",
    "        for test, statuses in test_statuses_dict.items():\n",
    "            if len(set(statuses)) == 1:\n",
    "                continue\n",
    "            df.loc[len(df.index)] = [mutation['mutatedClass'], mutation['mutatedMethod'], mutation['methodDescription'],\n",
    "                                     mutation['indexes'], mutation['mutator'], test] + statuses\n",
    "    df.to_csv(f'controlled_analyzed_data/{choice}/xml_results/{project}.csv', sep=',', header=True, index=False)\n",
    "    print(f'{project}: {cnt}/{len(muid_isConsistent_dict)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
