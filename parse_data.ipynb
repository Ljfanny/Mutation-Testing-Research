{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = [\n",
    "    # 'assertj-assertions-generator',\n",
    "    # 'commons-net',\n",
    "    'commons-cli',\n",
    "    'commons-csv',\n",
    "    'commons-codec',\n",
    "    'delight-nashorn-sandbox',\n",
    "    'empire-db',\n",
    "    'jimfs',\n",
    "    'httpcore',\n",
    "    'handlebars.java',\n",
    "    'riptide',\n",
    "    # 'commons-collections',\n",
    "    # 'guava',\n",
    "    # 'java-design-patterns',\n",
    "    # 'jooby',\n",
    "    # 'maven-dependency-plugin',\n",
    "    # 'maven-shade-plugin',\n",
    "    # 'sling-org-apache-sling-auth-core',\n",
    "    # 'stream-lib'\n",
    "]\n",
    "seed_list = [\n",
    "    # 0,\n",
    "    # 42,\n",
    "    # 123,\n",
    "    # 216,\n",
    "    # 1202,\n",
    "    # 1999,\n",
    "    # 2002,\n",
    "    # 2024,\n",
    "    # 31415,\n",
    "    # 99999,\n",
    "    'default',\n",
    "    # 'fastest',\n",
    "    # 'GC_test_order',\n",
    "    # 'M_fewest_tests',\n",
    "    # 'M_most_tests',\n",
    "    # 'M_most_coverage',\n",
    "    # 'M_most_similar',\n",
    "    # 'M_most_different',\n",
    "    # 'def_1_groups',\n",
    "    # 'def_2_groups',\n",
    "    # 'def_4_groups',\n",
    "    # 'def_6_groups',\n",
    "    # 'def_8_groups',\n",
    "    # 'def_10_groups',\n",
    "    # 'def_15_groups',\n",
    "    # 'def_20_groups',\n",
    "    # 'def_25_groups',\n",
    "    # 'def_30_groups',\n",
    "    # 'def_40_groups',\n",
    "    # 'def_50_groups',\n",
    "    # 'def_65_groups',\n",
    "    # 'def_80_groups',\n",
    "    # 'def_100_groups',\n",
    "    'clz_clz-cvg_def',\n",
    "    'clz_ln-cvg_def',\n",
    "    'n-tst_clz-cvg_def',\n",
    "    'n-tst_ln-cvg_def',\n",
    "    '01-tst_clz-cvg_def',\n",
    "    '01-tst_ln-cvg_def'\n",
    "]\n",
    "round_number = 6\n",
    "seed_number = len(seed_list)\n",
    "parsed_dir = 'controlled_parsed_data/both'\n",
    "analyzed_dir = 'controlled_analyzed_data/both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cols = ['class'] + seed_list + ['mean_deviation']\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as f:\n",
    "        id_tuple_dict = json.load(f)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as f:\n",
    "        id_runtimes_dict = json.load(f)\n",
    "    return id_tuple_dict, id_runtimes_dict\n",
    "\n",
    "\n",
    "for p in project_list:\n",
    "    df = pd.DataFrame(None, columns=cols)\n",
    "    is_visited = False\n",
    "    clz_runtimes_dict = dict()\n",
    "    for s in seed_list:\n",
    "        clz_ids_dict = dict()\n",
    "        id_tuple_dict, id_runtimes_dict = get_info(f'controlled_parsed_data/both/{p}_{s}')\n",
    "        with open(f'{analyzed_dir}/mutant_list/non-flaky/{p}_{s}.json', 'r') as f:\n",
    "            non_flaky_list = json.load(f)\n",
    "        if not is_visited:\n",
    "            is_visited = True\n",
    "            for mut_id in non_flaky_list:\n",
    "                mut_tup = id_tuple_dict[mut_id]\n",
    "                clz = mut_tup[0]\n",
    "                clz_runtimes_dict[clz] = []\n",
    "        for mut_id in non_flaky_list:\n",
    "            mut_tup = id_tuple_dict[mut_id]\n",
    "            clz = mut_tup[0]\n",
    "            if clz in clz_ids_dict:\n",
    "                clz_ids_dict[clz].append(mut_id)\n",
    "            else:\n",
    "                clz_ids_dict[clz] = [mut_id]\n",
    "        for clz, ids in clz_ids_dict.items():\n",
    "            total_runtime = 0\n",
    "            for mut_id in ids:\n",
    "                total_runtime += np.mean(id_runtimes_dict[mut_id])\n",
    "            clz_runtimes_dict[clz].append(math.ceil(total_runtime))\n",
    "    info_list = []\n",
    "    for clz, runtimes in clz_runtimes_dict.items():\n",
    "        avg_dev = round(np.mean([runtimes[0]/runtimes[i] for i in range(1, len(runtimes))]), 2)\n",
    "        info_list.append([clz] + runtimes + [avg_dev])\n",
    "    info_list.sort(key=lambda x: x[6], reverse=True)\n",
    "    for info in info_list:\n",
    "        df.loc[len(df.index)] = info\n",
    "    df.to_csv(f'{analyzed_dir}/total_runtime/each_clazz/{p}.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assertj-assertions-generator 13\n",
      "commons-cli 28\n",
      "commons-csv 10\n",
      "commons-codec 75\n",
      "delight-nashorn-sandbox 18\n",
      "empire-db 64\n",
      "jimfs 102\n",
      "handlebars.java 165\n",
      "httpcore 219\n",
      "riptide 44\n",
      "commons-net 86\n",
      "commons-collections 437\n",
      "guava 127\n",
      "java-design-patterns 4\n",
      "jooby 76\n",
      "maven-dependency-plugin 49\n",
      "maven-shade-plugin 32\n",
      "sling-org-apache-sling-auth-core 16\n",
      "stream-lib 44\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for p in project_list:\n",
    "    with open(f'parsed_data/default_version/{p}/mutantId_mutantTuple.json', 'r') as f:\n",
    "        id_tuple_dict = json.load(f)\n",
    "    clazz_set = set()\n",
    "    for i, t in id_tuple_dict.items():\n",
    "        clazz_set.add(t[0])\n",
    "    print(p, len(clazz_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'org.apache.commons.math4.legacy.core.dfp.DfpMathTest.testSin(org.apache.commons.math4.legacy.core.dfp.DfpMathTest)': ['org.apache.commons.math4.legacy.core.dfp.DfpMath'], 'org.apache.commons.math4.legacy.core.dfp.DfpMathTest.testPow(org.apache.commons.math4.legacy.core.dfp.DfpMathTest)': ['org.apache.commons.math4.legacy.core.dfp.DfpMath']}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# m1,m2,m3,m4....\n",
    "# t1, t2\n",
    "# t1 only covers lines in the mutated class\n",
    "# t2 never covers any line in the mutated class\n",
    "# if we run t1 on each mutant, would it run slow every single mutant? because the code it covers always has to be re-optimized due to hotswapping\n",
    "# meanwhile, if we run t2 on each mutant, would it run faster, since it doesn't depend on the mutated class that gets hotswapped\n",
    "# imagine large class\n",
    "# many, many lines -> many, many mutation possibilities\n",
    "# have one test that calls every method in the class\n",
    "# only covers lines in that class\n",
    "# another test that calls just one method or covers only one line in that class\n",
    "# but it calls methods in every other class there\n",
    "\n",
    "# mutated_clazz = 'org.apache.commons.math4.legacy.core.dfp.DfpMath'\n",
    "project_name = 'commons-math'\n",
    "junit_version = 'junit4'\n",
    "clazz_index = 0\n",
    "path = f'{project_name}/result'\n",
    "with open(f'{path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "    id_tuple_dict = json.load(file)\n",
    "with open(f'{path}/mutantId_runtimeList.json', 'r') as file:\n",
    "    id_runtimes_dict = json.load(file)\n",
    "with open(f'{path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "    id_tests_dict = json.load(file)\n",
    "\n",
    "test_clazzes_dict = dict()\n",
    "for mut_id, mut_tup in id_tuple_dict.items():\n",
    "    tests = id_tests_dict[mut_id]\n",
    "    clazz = mut_tup[clazz_index]\n",
    "    for t in tests:\n",
    "        if t in test_clazzes_dict:\n",
    "            test_clazzes_dict[t].append(clazz)\n",
    "        else:\n",
    "            test_clazzes_dict[t] = [clazz]\n",
    "\n",
    "test_clazzes_dict = {k: list(set(v)) for k, v in test_clazzes_dict.items()}\n",
    "print(test_clazzes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 Get total running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "choice = 'more_projects'\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as f:\n",
    "        id_runtimes_dict = json.load(f)\n",
    "    return id_runtimes_dict\n",
    "\n",
    "\n",
    "significant_df = pd.DataFrame(None, columns=['project', 'seed1', 'seed2', 'T-test', 'U-test'])\n",
    "for project in project_list:\n",
    "    columns = ['seed'] + [f'round{i}' for i in range(round_number)]\n",
    "    columns += ['avg.', '/avg. default', '/avg. fastest']\n",
    "    runtime_df = pd.DataFrame(None, columns=columns)\n",
    "    seed_runtimes_dict = {}\n",
    "    for seed in seed_list:\n",
    "        runtime_list = np.zeros(round_number, dtype=int)\n",
    "        with open(f'{analyzed_dir}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_id_list = json.load(f)\n",
    "        per_id_runtimes_dict = get_info(f'{parsed_dir}/{project}_{seed}')\n",
    "        for mut_id in non_flaky_id_list:\n",
    "            runtime_list += np.array(per_id_runtimes_dict[mut_id])\n",
    "        seed_runtimes_dict[seed] = runtime_list\n",
    "\n",
    "    avg_default = int(round(np.mean(seed_runtimes_dict['default'])))\n",
    "    # avg_fastest = int(round(np.mean(seed_runtimes_dict['fastest'])))\n",
    "    for i in range(seed_number):\n",
    "        seed1 = seed_list[i]\n",
    "        runtimes1 = seed_runtimes_dict[seed1]\n",
    "        avg_runtime = int(round(np.mean(runtimes1)))\n",
    "        ratio_vs_default = round(avg_runtime / avg_default, 3)\n",
    "        # ratio_vs_fastest = round(avg_runtime / avg_fastest, 3)\n",
    "        infos = [seed1] + list(runtimes1) + [f'{avg_runtime}', f'{ratio_vs_default}', f'']\n",
    "        runtime_df.loc[len(runtime_df.index)] = infos\n",
    "        for j in range(seed_number):\n",
    "            if j > i:\n",
    "                seed2 = seed_list[j]\n",
    "                runtimes2 = seed_runtimes_dict[seed2]\n",
    "                t_stat, t_p_value = ttest_ind(runtimes1, runtimes2)\n",
    "                u_stat, u_p_value = mannwhitneyu(runtimes1, runtimes2)\n",
    "                significant_df.loc[len(significant_df.index)] = [project, seed1, seed2, f'{t_p_value:.3f}', f'{u_p_value:.3f}']\n",
    "    runtime_df.to_csv(f'{analyzed_dir}/total_runtime/{project}.csv', sep=',', header=True, index=False)\n",
    "significant_df.to_csv(f'{analyzed_dir}/total_runtime/significant_results.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Calculate T-test, U-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='Precision loss occurred in moment calculation.')\n",
    "\n",
    "\n",
    "def get_info(project, seed):\n",
    "    path = f'{parsed_path}/{choice}/{project}_{seed}'\n",
    "    with open(f'{path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "def to_be_calculable(runtime_list):\n",
    "    output_list = []\n",
    "    for runtime in runtime_list:\n",
    "        if runtime == TIMED_OUT:\n",
    "            output_list.append(6000)\n",
    "        else:\n",
    "            output_list.append(runtime)\n",
    "    return output_list\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    seed_mutants_dict = {}\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(project, seed)\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        seed_mutants_dict[seed] = {}\n",
    "        for mutant_id in non_flaky_list:\n",
    "            mutant_pref = tuple(mutantId_mutantTuple_dict[mutant_id][:5])\n",
    "            seed_mutants_dict[seed][mutant_pref] = to_be_calculable(mutantId_runtimeList_dict[mutant_id])\n",
    "    for i in range(seed_number):\n",
    "        i_seed = seed_list[i]\n",
    "        i_mutants_dict = seed_mutants_dict[i_seed]\n",
    "        j = i + 1\n",
    "        while j < seed_number:\n",
    "            df = pd.DataFrame(None, columns=['mutant', 'T-test', 'U-test'])\n",
    "            j_seed = seed_list[j]\n",
    "            j_mutants_dict = seed_mutants_dict[j_seed]\n",
    "            significant_number = 0\n",
    "            for pref, i_runtime_list in i_mutants_dict.items():\n",
    "                j_runtime_list = j_mutants_dict[pref]\n",
    "                t_stat, t_p_value = ttest_ind(i_runtime_list, j_runtime_list)\n",
    "                u_stat, u_p_value = mannwhitneyu(i_runtime_list, j_runtime_list)\n",
    "                if t_p_value < 0.05 or u_p_value < 0.05:\n",
    "                    significant_number += 1\n",
    "                df.loc[len(df.index)] = [pref, t_p_value, u_p_value]\n",
    "            # df.to_csv(f'{analyzed_path}/{choice}/significance_detection/non-flaky/{project}_{i_seed}_{j_seed}.csv', sep=',', header=True, index=False)\n",
    "            j += 1\n",
    "            print(f'{project} with ({i_seed}, {j_seed}): {significant_number}/{len(non_flaky_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    total_flaky_tests = set()\n",
    "    for seed in seed_list:\n",
    "        flaky_chaotic_order_mutant_list = []\n",
    "        total_num = 0\n",
    "        non_flaky_num = 0\n",
    "        flaky_chaotic_order_num = 0\n",
    "        uniqueId_mutantIds_dict = {}\n",
    "        mutantId_mutantTuple_dict, mutantId_testsInOrder_dict, mutantId_runtimeList_dict = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            unique_id = tuple(mutant_tuple[:5])\n",
    "            test_list = mutantId_testsInOrder_dict[mutant_id]\n",
    "            if unique_id not in uniqueId_mutantIds_dict:\n",
    "                uniqueId_mutantIds_dict[unique_id] = set()\n",
    "            uniqueId_mutantIds_dict[unique_id].add(mutant_id)\n",
    "        total_num = len(uniqueId_mutantIds_dict)\n",
    "        for unique_id, mutant_ids in uniqueId_mutantIds_dict.items():\n",
    "            if len(mutant_ids) == 1:\n",
    "                non_flaky_num += 1\n",
    "            else:\n",
    "                test_intersection_set = None\n",
    "                for mutant_id in mutant_ids:\n",
    "                    per_test_set = set(mutantId_testsInOrder_dict[mutant_id])\n",
    "                    if test_intersection_set is None:\n",
    "                        test_intersection_set = per_test_set\n",
    "                    else:\n",
    "                        test_intersection_set &= per_test_set\n",
    "                is_same = True\n",
    "                flaky_tests = set()\n",
    "                for mutant_id in mutant_ids:\n",
    "                    per_test_set = set(mutantId_testsInOrder_dict[mutant_id])\n",
    "                    if len(per_test_set) == len(test_intersection_set):\n",
    "                        continue\n",
    "                    flaky_tests |= (per_test_set - test_intersection_set)\n",
    "                if len(flaky_tests) == 0:\n",
    "                    flaky_chaotic_order_num += 1\n",
    "                    flaky_chaotic_order_mutant_list.append(random.choice(list(mutant_ids)))\n",
    "                total_flaky_tests |= flaky_tests\n",
    "        # with open(f'analyzed_data/{choice}/mutant_list/chaotic_order/{project}_{seed}.json', 'w') as file:\n",
    "        #     json.dump(flaky_chaotic_order_mutant_list, file, indent=4)\n",
    "    \n",
    "        print(f'{project} with {seed}:')\n",
    "        print(f'Total mutants: {total_num}')\n",
    "        print(f'Non-flaky mutants: {non_flaky_num} ({non_flaky_num / total_num:.4f})')\n",
    "        print(f'Flaky mutants due to chaotic test list: {flaky_chaotic_order_num} ({flaky_chaotic_order_num / total_num:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create guiding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict, mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    def test_sort(test):\n",
    "        return (test['name'])\n",
    "    \n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    if random_test:\n",
    "        random.shuffle(test_order)\n",
    "    else:\n",
    "        test_order.sort(key=test_sort)\n",
    "\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'filename': mutant[5],\n",
    "        'block': f'[{mutant[6]}]',\n",
    "        'lineNumber': int(mutant[7]),\n",
    "        'description': mutant[8],\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "\n",
    "\n",
    "parent_path = f'analyzed_data/{choice}/mutant_list'\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    # get the mutant intersection\n",
    "    id_set = set()\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, _ = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        with open(f'{parent_path}/chaotic_order/{project}_{seed}.json', 'r') as file:\n",
    "            chaotic_order_list = json.load(file)\n",
    "        per_id_set = set()\n",
    "        for mutant_id in chaotic_order_list:\n",
    "            per_id_set.add(tuple(mutantId_mutantTuple_dict[mutant_id][:5]))\n",
    "        if len(id_set) == 0:\n",
    "            id_set |= per_id_set\n",
    "        else:\n",
    "            id_set &= per_id_set\n",
    "    # create guiding mutant list\n",
    "    for seed in seed_list:\n",
    "        with open(f'{parent_path}/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        mutantId_mutantTuple_dict, mutantId_testsInOrder_dict = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        output_list = []\n",
    "        id_visited_dict = {item: True for item in id_set}\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            id_tuple = tuple(mutant_tuple[:5])\n",
    "            if mutant_id in non_flaky_list or (id_tuple in id_set and id_visited_dict[id_tuple]):\n",
    "                if id_tuple in id_set:\n",
    "                    id_visited_dict[id_tuple] = False\n",
    "                output_list.append(mutant_to_json(mutant=mutant_tuple,\n",
    "                                                  test_list=mutantId_testsInOrder_dict[mutant_id],\n",
    "                                                  junit_version=junit_version))\n",
    "        if random_mutant:\n",
    "            random.shuffle(output_list)\n",
    "        else:\n",
    "            output_list.sort(key=mutant_sort)\n",
    "        with open(f'analyzed_data/{choice}/guiding_files/{project}_{seed}.json', 'w') as f:\n",
    "            f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choose fastest test order to guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "seeds = [0, 42, 123, 216, 1202, 1999, 2002, 2024, 31415, 99999]\n",
    "choice = 'more_projects'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict, mutantId_testsInOrder_dict\n",
    "    \n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "    \n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "for project in ['commons-cli']:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    mutation_runtimes_dict = {}\n",
    "    mutation_tests_dict = {}\n",
    "    is_recorded = False\n",
    "    for seed in seeds:\n",
    "        with open(f'{analyzed_dir}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_list = json.load(f)\n",
    "        id_tuple_dict, id_runtimes_dict, id_tests_dict = get_info(f'{parsed_dir}/{choice}/{project}_{seed}')\n",
    "        for mut_id in non_flaky_list:\n",
    "            mut = tuple(id_tuple_dict[mut_id])\n",
    "            runtime_list = id_runtimes_dict[mut_id]\n",
    "            runtime = round(np.mean(runtime_list))\n",
    "            if is_recorded:\n",
    "                mutation_runtimes_dict[mut].append(runtime)\n",
    "                mutation_tests_dict[mut].append(id_tests_dict[mut_id])\n",
    "            else:\n",
    "                mutation_runtimes_dict[mut] = [runtime]\n",
    "                mutation_tests_dict[mut] = [id_tests_dict[mut_id]]\n",
    "        is_recorded = True\n",
    "    output_list = []\n",
    "    for mut, runtimes in mutation_runtimes_dict.items():\n",
    "        tests = mutation_tests_dict[mut]\n",
    "        mini = 1000000\n",
    "        mini_index = -1\n",
    "        for i in range(len(seeds)):\n",
    "            if runtimes[i] < mini:\n",
    "                mini = runtimes[i]\n",
    "                mini_index = i\n",
    "        output_list.append(mutant_to_json(mutant=mut,\n",
    "                                          test_list=tests[mini_index],\n",
    "                                          junit_version=junit_version))\n",
    "    output_list.sort(key=mutant_sort)\n",
    "    with open(f'{analyzed_dir}/{choice}/guiding_files/{project}_fastest.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate input files based on single default result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    # random.shuffle(test_order)\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'filename': mutant[5],\n",
    "        'block': f'[{mutant[6]}]',\n",
    "        'lineNumber': int(mutant[7]),\n",
    "        'description': mutant[8],\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'parsed_data/default_version/{project}')\n",
    "    for seed in seed_list:\n",
    "        # random.seed(seed)\n",
    "        seed = 'default'\n",
    "        output_list = []\n",
    "        for mut_id, mut_tup in id_tuple_dict.items():\n",
    "            output_list.append(mutant_to_json(mutant=mut_tup,\n",
    "                                              test_list=id_tests_dict[mut_id],\n",
    "                                              junit_version=junit_version))\n",
    "        output_list.sort(key=mutant_sort)\n",
    "        with open(f'analyzed_data/default_version/guiding_files/{project}_{seed}.json', 'w') as f:\n",
    "            f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check the order of mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from flakiness_filter import clazz_index\n",
    "choice = 'more_projects'\n",
    "\n",
    "\n",
    "print('For each clazz (each process):')\n",
    "for project in project_list:\n",
    "    clazz_orders_dict = dict()\n",
    "    for seed in seed_list:\n",
    "        cur_clazz_orders_dict = dict()\n",
    "        with open(f'{parsed_dir}/{choice}/{project}_{seed}/mutantId_mutantTuple.json', 'r') as f:\n",
    "            id_tuple_dict = json.load(f)\n",
    "        with open(f'{analyzed_dir}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_id_list = json.load(f)\n",
    "\n",
    "        for mut_id in non_flaky_id_list:\n",
    "                mut_tup = id_tuple_dict[mut_id]\n",
    "                clazz = mut_tup[clazz_index]\n",
    "                if clazz in cur_clazz_orders_dict:\n",
    "                    cur_clazz_orders_dict[clazz].append(mut_tup)\n",
    "                else:\n",
    "                    cur_clazz_orders_dict[clazz] = [mut_tup]\n",
    "        diff_cnt = 0\n",
    "        if len(clazz_orders_dict) == 0:\n",
    "            clazz_orders_dict = cur_clazz_orders_dict\n",
    "        else:\n",
    "            for clazz, mutant_order in clazz_orders_dict.items():\n",
    "                if mutant_order != cur_clazz_orders_dict[clazz]:\n",
    "                    diff_cnt += 1\n",
    "        if diff_cnt > 0:\n",
    "            print(f'The diff cnt of {project} with {seed}: {diff_cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Average runtime (per mutant) table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "choice = 'more_projects'\n",
    "cols = ['clazz', 'method', 'methodDesc', 'indexes', 'mutator'] + [f'{s}' for s in seed_list]\n",
    "for project in project_list:\n",
    "    df = pd.DataFrame(None, columns=cols)\n",
    "    mutant_runtimes_dict = dict()\n",
    "    is_recorded = False\n",
    "    for seed in seed_list:\n",
    "        id_tuple_dict, id_runtimes_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_id_list = json.load(f)\n",
    "        for mut_id in non_flaky_id_list:\n",
    "            mut_tup = tuple(id_tuple_dict[mut_id])\n",
    "            avg_runtime = round(np.mean(id_runtimes_dict[mut_id]))\n",
    "            if is_recorded:\n",
    "                mutant_runtimes_dict[mut_tup].append(avg_runtime)\n",
    "            else:\n",
    "                mutant_runtimes_dict[mut_tup] = [avg_runtime]\n",
    "        is_recorded = True\n",
    "    for mut, avg_runtimes in mutant_runtimes_dict.items():\n",
    "        df.loc[len(df.index)] = list(mut) + avg_runtimes\n",
    "    df.to_csv(f'{analyzed_path}/{choice}/runtime_per_mutant/{project}.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Based on test scores\n",
    "score = w_kill * kill_ratio + w_cover * cover_ratio \\\n",
    "w_kill + w_cover = 1\n",
    "\n",
    "For kill_ratio: \\\n",
    "A test covers n mutants, and it can kill m(0≤m≤n) mutants, then kill_ratio = m / n; \\\n",
    "For cover_ratio: \\\n",
    "There are n mutants from a class, and a test can cover m mutants(0≤m≤n), then cover_ratio = m / n;\n",
    "\n",
    "The higher the score, the better the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "choice = 'more_projects'\n",
    "clazz_index = 0\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict\n",
    "    \n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "    \n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    with open(f'{analyzed_dir}/{choice}/mutant_list/non-flaky/{project}_default.json', 'r') as f:\n",
    "        non_flaky_id_list = json.load(f)\n",
    "    with open(f'{analyzed_dir}/{choice}/test_scores/{project}.json', 'r') as f:\n",
    "        test_score_dict = {eval(k): v for k, v in json.load(f).items()}\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'{parsed_dir}/{choice}/{project}_default')\n",
    "    output_list = []\n",
    "    for mut_id in non_flaky_id_list:\n",
    "        index_score_tup_list = []\n",
    "        mut_tup = id_tuple_dict[mut_id]\n",
    "        clazz = mut_tup[clazz_index]\n",
    "        tests = id_tests_dict[mut_id]\n",
    "        for i, t in enumerate(tests):\n",
    "            index_score_tup_list.append((i, test_score_dict[(clazz, t)]))\n",
    "        index_score_tup_list.sort(key=lambda x: x[1], reverse=True)\n",
    "        test_list = []\n",
    "        num = math.ceil(0.5 * (i + 1))\n",
    "        for i in range(num):\n",
    "            test_list.append(tests[index_score_tup_list[i][0]])\n",
    "        output_list.append(mutant_to_json(mutant=mut_tup,\n",
    "                                          test_list=test_list,\n",
    "                                          junit_version=junit_version))\n",
    "        output_list.sort(key=mutant_sort)\n",
    "        with open(f'{analyzed_dir}/{choice}/guiding_files/{project}_half.json', 'w') as f:\n",
    "            f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the result?\n",
    "import json\n",
    "import numpy as np\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "choice = 'more_projects'\n",
    "clazz_index = 0\n",
    "method_index = 1\n",
    "methodDesc_index = 2\n",
    "indexes_index = 3\n",
    "mutator_index = 4\n",
    "STATUS = 'status'\n",
    "KILLED = 'KILLED'\n",
    "SURVIVED = 'SURVIVED'\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutations_xml.json', 'r') as file:\n",
    "        mutants = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict, mutants\n",
    "\n",
    "\n",
    "def xml_to_key(obj):\n",
    "    return (obj['mutatedClass'],\n",
    "            obj['mutatedMethod'],\n",
    "            obj['methodDescription'],\n",
    "            str([int(i) for i in obj['indexes']]),\n",
    "            obj['mutator'])\n",
    "\n",
    "\n",
    "def log_to_key(obj):\n",
    "    return (obj[clazz_index],\n",
    "            obj[method_index],\n",
    "            obj[methodDesc_index],\n",
    "            str([int(i) for i in obj[indexes_index].split(', ')]),\n",
    "            obj[mutator_index])\n",
    "\n",
    "\n",
    "def get_deleted_result(file_path, idx, title):\n",
    "    id_tuple_dict, id_runtimes_dict, xml_infos_list = get_info(file_path)\n",
    "    non_flaky_mutants = set()\n",
    "    for mut_id, runtimes in id_runtimes_dict.items():\n",
    "        if np.isnan(runtimes).any():\n",
    "            continue\n",
    "        non_flaky_mutants.add(log_to_key(id_tuple_dict[mut_id]))\n",
    "    killed_num = 0\n",
    "    for mut in xml_infos_list:\n",
    "        if xml_to_key(mut) in non_flaky_mutants:\n",
    "            if mut[STATUS] == KILLED:\n",
    "                killed_num += 1\n",
    "    print(f'{idx}. {title} test(s) with the highest score: {killed_num} / {len(non_flaky_mutants)} = {killed_num / len(non_flaky_mutants):.3f}')\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    mutants = set()\n",
    "    is_recorded = False\n",
    "    print(f'For {project}:')\n",
    "    for i, seed in enumerate(seed_list):\n",
    "        with open(f'{analyzed_dir}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_id_list = json.load(f)\n",
    "        id_tuple_dict, id_runtimes_dict, xml_infos_list = get_info(f'{parsed_dir}/{choice}/{project}_{seed}')\n",
    "        if not is_recorded:\n",
    "            for mut_id in non_flaky_id_list:\n",
    "                mut_tup = id_tuple_dict[mut_id]\n",
    "                mutants.add(log_to_key(mut_tup))\n",
    "        killed_num = 0\n",
    "        for mut in xml_infos_list:\n",
    "            if xml_to_key(mut) in mutants:\n",
    "                if mut[STATUS] == KILLED:\n",
    "                    killed_num += 1\n",
    "        print(f'{i + 1}. Seed is {seed}: {killed_num} / {len(mutants)} = {killed_num / len(mutants):.3f}')\n",
    "    get_deleted_result(f'{parsed_dir}/{choice}/{project}_single', i + 2, 'Single')\n",
    "    get_deleted_result(f'{parsed_dir}/{choice}/{project}_half', i + 3, 'Half')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Reorder mutants or tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep mutant order.\n",
    "import numpy as np\n",
    "import copy\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "choice = 'more_projects'\n",
    "clazz_index = 0\n",
    "tests_index = 5\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return mutant[:5]\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as f:\n",
    "        id_tuple_dict = json.load(f)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as f:\n",
    "        id_tests_dict = json.load(f)\n",
    "    return id_tuple_dict, id_tests_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index - 1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'parsed_data/default_version/{project}')\n",
    "    reordered_mutants = list()\n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        mut = mut_tup[:5] + [id_tests_dict[mut_id]]\n",
    "        reordered_mutants.append(mut)\n",
    "    reordered_mutants.sort(key=mutant_sort)\n",
    "    output_list = list()\n",
    "    recorded_clazz_set = set()\n",
    "    stack = list()\n",
    "    for mut in reordered_mutants:\n",
    "        clazz = mut[clazz_index]\n",
    "        tests = mut[tests_index]\n",
    "        if clazz in recorded_clazz_set:\n",
    "            reordered_tests = list()\n",
    "            cur_stack = list()\n",
    "            remains = copy.deepcopy(tests)\n",
    "            while len(stack) > 0:\n",
    "                t = stack.pop()\n",
    "                if t in tests:\n",
    "                    reordered_tests.append(t)\n",
    "                    cur_stack.append(t)\n",
    "                    remains.remove(t)\n",
    "            reordered_tests += remains\n",
    "            stack = cur_stack + remains\n",
    "            output_list.append(mutant_to_json(mutant=mut,\n",
    "                                              test_list=reordered_tests,\n",
    "                                              junit_version=project_junitVersion_dict[project]))\n",
    "        else:\n",
    "            recorded_clazz_set.add(clazz)\n",
    "            stack = list()\n",
    "            for t in tests:\n",
    "                stack.append(t)\n",
    "            output_list.append(mutant_to_json(mutant=mut,\n",
    "                                              test_list=tests,\n",
    "                                              junit_version=project_junitVersion_dict[project]))\n",
    "    with open(f'{analyzed_dir}/{choice}/guiding_files/{project}_GC_torder.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep test order: with the most tests\n",
    "import copy\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "choice = 'more_projects'\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        -len(mutant['testsInOrder'])\n",
    "    )\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as f:\n",
    "        id_tuple_dict = json.load(f)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as f:\n",
    "        id_tests_dict = json.load(f)\n",
    "    return id_tuple_dict, id_tests_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index - 1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'parsed_data/default_version/{project}')\n",
    "    output_list = list()\n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        output_list.append(mutant_to_json(mutant=mut_tup,\n",
    "                                          test_list=id_tests_dict[mut_id],\n",
    "                                          junit_version=project_junitVersion_dict[project]))\n",
    "    output_list.sort(key=mutant_sort)\n",
    "    with open(f'{analyzed_dir}/{choice}/guiding_files/{project}_GC_morder.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep test order: with the fewest tests\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "choice = 'more_projects'\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        len(mutant['testsInOrder'])\n",
    "    )\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as f:\n",
    "        id_tuple_dict = json.load(f)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as f:\n",
    "        id_tests_dict = json.load(f)\n",
    "    return id_tuple_dict, id_tests_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index - 1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'parsed_data/default_version/{project}')\n",
    "    output_list = list()\n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        output_list.append(mutant_to_json(mutant=mut_tup,\n",
    "                                          test_list=id_tests_dict[mut_id],\n",
    "                                          junit_version=project_junitVersion_dict[project]))\n",
    "    output_list.sort(key=mutant_sort)\n",
    "    with open(f'{analyzed_dir}/{choice}/guiding_files/{project}_M_fewest_tests.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep test order: with the most coverage\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "choice = 'more_projects'\n",
    "clazz_index = 0\n",
    "lineNum_index = 7\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        -mutant['metric']\n",
    "    )\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        -mutant['metric']\n",
    "    )\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as f:\n",
    "        id_tuple_dict = json.load(f)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as f:\n",
    "        id_tests_dict = json.load(f)\n",
    "    return id_tuple_dict, id_tests_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    mut_set = set()\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            mut_set |= set(test_ids_dict[test])\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            mut_set |= set(test_ids_dict[test])\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index - 1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order,\n",
    "        'metric': len(mut_set)\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'parsed_data/default_version/{project}')\n",
    "    output_list = list()\n",
    "    test_ids_dict = dict()\n",
    "    test_clazzes_dict = dict()\n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        tests = id_tests_dict[mut_id]\n",
    "        clazz = mut_tup[clazz_index]\n",
    "        for t in tests:\n",
    "            if t in test_ids_dict:\n",
    "                test_clazzes_dict[t].append(clazz)\n",
    "                test_ids_dict[t].append(mut_id)\n",
    "            else:\n",
    "                test_clazzes_dict[t] = [clazz]\n",
    "                test_ids_dict[t] = [mut_id]\n",
    "    \n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        output_list.append(mutant_to_json(mutant=mut_tup,\n",
    "                                          test_list=id_tests_dict[mut_id],\n",
    "                                          junit_version=project_junitVersion_dict[project]))\n",
    "    output_list.sort(key=mutant_sort)\n",
    "    # with open(f'{analyzed_dir}/{choice}/guiding_files/{project}_M_most_coverage.json', 'w') as f:\n",
    "    #     f.write(json.dumps(output_list, indent=4))\n",
    "\n",
    "    tmp = list()\n",
    "    for t, clazzes in test_clazzes_dict.items():\n",
    "        tmp.append([t, len(set(clazzes)), len(set(test_ids_dict[t]))])\n",
    "    tmp.sort(key=lambda x: x[0])\n",
    "    with open(f'controlled_analyzed_data/{choice}/extra/{project}_linesVSclazzes.json', 'w') as f:\n",
    "        f.write(json.dumps(tmp, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep test order: with the most similar\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "choice = 'more_projects'\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz']\n",
    "    )\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as f:\n",
    "        id_tuple_dict = json.load(f)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as f:\n",
    "        id_tests_dict = json.load(f)\n",
    "    return id_tuple_dict, id_tests_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    mut_set = set()\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            mut_set |= set(test_ids_dict[test])\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            mut_set |= set(test_ids_dict[test])\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index - 1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order,\n",
    "        'metric': tuple(mut_set)\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'parsed_data/default_version/{project}')\n",
    "    test_ids_dict = dict()\n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        tests = id_tests_dict[mut_id]\n",
    "        for t in tests:\n",
    "            if t in test_ids_dict:\n",
    "                test_ids_dict[t].append(mut_id)\n",
    "            else:\n",
    "                test_ids_dict[t] = [mut_id]\n",
    "    mutant_list = list()\n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        mutant_list.append(mutant_to_json(mutant=mut_tup,\n",
    "                                          test_list=id_tests_dict[mut_id],\n",
    "                                          junit_version=project_junitVersion_dict[project]))\n",
    "    mutant_list.sort(key=mutant_sort)\n",
    "    resorted_list = list()\n",
    "    mutant_num = len(mutant_list)\n",
    "    cur_clazz = ''\n",
    "    is_next = False\n",
    "    i = 0\n",
    "    while i < mutant_num:\n",
    "        mut = mutant_list[i]\n",
    "        cur_set = set()\n",
    "        if not is_next:\n",
    "            is_next = True\n",
    "            cur_clazz = mut['id']['location']['clazz']\n",
    "            resorted_list.append(mut)\n",
    "            cur_set = mut['metric']\n",
    "            i += 1\n",
    "        cur_mutants = list()\n",
    "        while is_next and i < mutant_num:\n",
    "            mut = mutant_list[i]\n",
    "            if cur_clazz != mut['id']['location']['clazz']:\n",
    "                is_next = False\n",
    "                break\n",
    "            cur_mutants.append(mut)\n",
    "            i += 1\n",
    "        while len(cur_mutants) > 0:\n",
    "            best = 0\n",
    "            best_idx = -1\n",
    "            for j, mut in enumerate(cur_mutants):\n",
    "                cnt = len(set(mut['metric']) & set(cur_set))\n",
    "                if cnt > best:\n",
    "                    best = cnt\n",
    "                    best_idx = j\n",
    "            resorted_list.append(cur_mutants[best_idx])\n",
    "            cur_mutants.pop(best_idx)\n",
    "            cur_set = resorted_list[-1]['metric']\n",
    "    output_list = list()\n",
    "    for mut in resorted_list:\n",
    "        output_list.append({\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mut['id']['location']['clazz'],\n",
    "                'method': mut['id']['location']['method'],\n",
    "                'methodDesc': mut['id']['location']['methodDesc']\n",
    "            },\n",
    "            'indexes': mut['id']['indexes'],\n",
    "            'mutator': mut['id']['mutator']\n",
    "        },\n",
    "        'testsInOrder': mut['testsInOrder']\n",
    "    })  \n",
    "    with open(f'{analyzed_dir}/{choice}/guiding_files/{project}_M_most_similar.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep test order: with the most different\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "choice = 'more_projects'\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz']\n",
    "    )\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as f:\n",
    "        id_tuple_dict = json.load(f)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as f:\n",
    "        id_tests_dict = json.load(f)\n",
    "    return id_tuple_dict, id_tests_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    mut_set = set()\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            mut_set |= set(test_ids_dict[test])\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            mut_set |= set(test_ids_dict[test])\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index - 1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order,\n",
    "        'metric': tuple(mut_set)\n",
    "    }\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'parsed_data/default_version/{project}')\n",
    "    test_ids_dict = dict()\n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        tests = id_tests_dict[mut_id]\n",
    "        for t in tests:\n",
    "            if t in test_ids_dict:\n",
    "                test_ids_dict[t].append(mut_id)\n",
    "            else:\n",
    "                test_ids_dict[t] = [mut_id]\n",
    "    mutant_list = list()\n",
    "    for mut_id, mut_tup in id_tuple_dict.items():\n",
    "        mutant_list.append(mutant_to_json(mutant=mut_tup,\n",
    "                                          test_list=id_tests_dict[mut_id],\n",
    "                                          junit_version=project_junitVersion_dict[project]))\n",
    "    mutant_list.sort(key=mutant_sort)\n",
    "    resorted_list = list()\n",
    "    mutant_num = len(mutant_list)\n",
    "    cur_clazz = ''\n",
    "    is_next = False\n",
    "    i = 0\n",
    "    while i < mutant_num:\n",
    "        mut = mutant_list[i]\n",
    "        cur_set = set()\n",
    "        if not is_next:\n",
    "            is_next = True\n",
    "            cur_clazz = mut['id']['location']['clazz']\n",
    "            resorted_list.append(mut)\n",
    "            cur_set = mut['metric']\n",
    "            i += 1\n",
    "        cur_mutants = list()\n",
    "        while is_next and i < mutant_num:\n",
    "            mut = mutant_list[i]\n",
    "            if cur_clazz != mut['id']['location']['clazz']:\n",
    "                is_next = False\n",
    "                break\n",
    "            cur_mutants.append(mut)\n",
    "            i += 1\n",
    "        while len(cur_mutants) > 0:\n",
    "            worse = 10000\n",
    "            worse_idx = -1\n",
    "            for j, mut in enumerate(cur_mutants):\n",
    "                cnt = len(set(mut['metric']) & set(cur_set))\n",
    "                if cnt < worse:\n",
    "                    worse = cnt\n",
    "                    worse_idx = j\n",
    "            resorted_list.append(cur_mutants[worse_idx])\n",
    "            cur_mutants.pop(worse_idx)\n",
    "            cur_set = resorted_list[-1]['metric']\n",
    "    output_list = list()\n",
    "    for mut in resorted_list:\n",
    "        output_list.append({\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mut['id']['location']['clazz'],\n",
    "                'method': mut['id']['location']['method'],\n",
    "                'methodDesc': mut['id']['location']['methodDesc']\n",
    "            },\n",
    "            'indexes': mut['id']['indexes'],\n",
    "            'mutator': mut['id']['mutator']\n",
    "        },\n",
    "        'testsInOrder': mut['testsInOrder']\n",
    "    })  \n",
    "    with open(f'{analyzed_dir}/{choice}/guiding_files/{project}_M_most_different.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIProj3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
