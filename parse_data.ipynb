{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_list = [\n",
    "    'assertj-assertions-generator',\n",
    "    'commons-cli',\n",
    "    'commons-csv',\n",
    "    'commons-codec',\n",
    "    'delight-nashorn-sandbox',\n",
    "    'empire-db',\n",
    "    'jimfs',\n",
    "    # 'handlebars.java',\n",
    "    # 'httpcore',\n",
    "    # 'riptide',\n",
    "\n",
    "    # 'commons-net',\n",
    "    # 'commons-collections',\n",
    "    # 'commons-net',\n",
    "    # 'empire-db',\n",
    "    # 'guava',\n",
    "    # 'java-design-patterns',\n",
    "    # 'jooby',\n",
    "    # 'maven-dependency-plugin',\n",
    "    # 'maven-shade-plugin',\n",
    "    # 'sling-org-apache-sling-auth-core',\n",
    "    # 'stream-lib'\n",
    "]\n",
    "seed_list = [\n",
    "    0,\n",
    "    42,\n",
    "    123,\n",
    "    216,\n",
    "    1202,\n",
    "    1999,\n",
    "    2002,\n",
    "    2024,\n",
    "    31415,\n",
    "    99999,\n",
    "    'default',\n",
    "    'fastest'\n",
    "]\n",
    "round_number = 6\n",
    "seed_number = len(seed_list)\n",
    "parsed_path = 'controlled_parsed_data'\n",
    "analyzed_path = 'controlled_analyzed_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 Get total running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as f:\n",
    "        id_runtimes_dict = json.load(f)\n",
    "    return id_runtimes_dict\n",
    "\n",
    "\n",
    "choice = 'more_projects'\n",
    "significant_df = pd.DataFrame(None, columns=['project', 'seed1', 'seed2', 'T-test', 'U-test'])\n",
    "for project in project_list:\n",
    "    columns = ['seed'] + [f'round{i}' for i in range(round_number)]\n",
    "    columns += ['avg.', '/avg. default', '/avg. fastest']\n",
    "    runtime_df = pd.DataFrame(None, columns=columns)\n",
    "    seed_runtimes_dict = {}\n",
    "    for seed in seed_list:\n",
    "        runtime_list = np.zeros(round_number, dtype=int)\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_id_list = json.load(f)\n",
    "        per_id_runtimes_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mut_id in non_flaky_id_list:\n",
    "            runtime_list += np.array(per_id_runtimes_dict[mut_id])\n",
    "        seed_runtimes_dict[seed] = runtime_list\n",
    "\n",
    "    avg_default = int(round(np.mean(seed_runtimes_dict['default'])))\n",
    "    avg_fastest = int(round(np.mean(seed_runtimes_dict['fastest'])))\n",
    "    for i in range(seed_number):\n",
    "        seed1 = seed_list[i]\n",
    "        runtimes1 = seed_runtimes_dict[seed1]\n",
    "        avg_runtime = int(round(np.mean(runtimes1)))\n",
    "        ratio_vs_default = round(avg_runtime / avg_default, 3)\n",
    "        ratio_vs_fastest = round(avg_runtime / avg_fastest, 3)\n",
    "        infos = [seed1] + list(runtimes1) + [f'{avg_runtime}', f'{ratio_vs_default}', f'{ratio_vs_fastest}']\n",
    "        runtime_df.loc[len(runtime_df.index)] = infos\n",
    "        for j in range(seed_number):\n",
    "            if j > i:\n",
    "                seed2 = seed_list[j]\n",
    "                runtimes2 = seed_runtimes_dict[seed2]\n",
    "                t_stat, t_p_value = ttest_ind(runtimes1, runtimes2)\n",
    "                u_stat, u_p_value = mannwhitneyu(runtimes1, runtimes2)\n",
    "                significant_df.loc[len(significant_df.index)] = [project, seed1, seed2, f'{t_p_value:.3f}', f'{u_p_value:.3f}']\n",
    "    runtime_df.to_csv(f'{analyzed_path}/{choice}/total_runtime/{project}.csv', sep=',', header=True, index=False)\n",
    "significant_df.to_csv(f'{analyzed_path}/{choice}/total_runtime/significant_results.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Calculate T-test, U-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import json\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='Precision loss occurred in moment calculation.')\n",
    "\n",
    "\n",
    "def get_info(project, seed):\n",
    "    path = f'{parsed_path}/{choice}/{project}_{seed}'\n",
    "    with open(f'{path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "def to_be_calculable(runtime_list):\n",
    "    output_list = []\n",
    "    for runtime in runtime_list:\n",
    "        if runtime == TIMED_OUT:\n",
    "            output_list.append(6000)\n",
    "        else:\n",
    "            output_list.append(runtime)\n",
    "    return output_list\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    seed_mutants_dict = {}\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, mutantId_runtimeList_dict = get_info(project, seed)\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        seed_mutants_dict[seed] = {}\n",
    "        for mutant_id in non_flaky_list:\n",
    "            mutant_pref = tuple(mutantId_mutantTuple_dict[mutant_id][:5])\n",
    "            seed_mutants_dict[seed][mutant_pref] = to_be_calculable(mutantId_runtimeList_dict[mutant_id])\n",
    "    for i in range(seed_number):\n",
    "        i_seed = seed_list[i]\n",
    "        i_mutants_dict = seed_mutants_dict[i_seed]\n",
    "        j = i + 1\n",
    "        while j < seed_number:\n",
    "            df = pd.DataFrame(None, columns=['mutant', 'T-test', 'U-test'])\n",
    "            j_seed = seed_list[j]\n",
    "            j_mutants_dict = seed_mutants_dict[j_seed]\n",
    "            significant_number = 0\n",
    "            for pref, i_runtime_list in i_mutants_dict.items():\n",
    "                j_runtime_list = j_mutants_dict[pref]\n",
    "                t_stat, t_p_value = ttest_ind(i_runtime_list, j_runtime_list)\n",
    "                u_stat, u_p_value = mannwhitneyu(i_runtime_list, j_runtime_list)\n",
    "                if t_p_value < 0.05 or u_p_value < 0.05:\n",
    "                    significant_number += 1\n",
    "                df.loc[len(df.index)] = [pref, t_p_value, u_p_value]\n",
    "            # df.to_csv(f'{analyzed_path}/{choice}/significance_detection/non-flaky/{project}_{i_seed}_{j_seed}.csv', sep=',', header=True, index=False)\n",
    "            j += 1\n",
    "            print(f'{project} with ({i_seed}, {j_seed}): {significant_number}/{len(non_flaky_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from pitest_log_parser import mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    total_flaky_tests = set()\n",
    "    for seed in seed_list:\n",
    "        flaky_chaotic_order_mutant_list = []\n",
    "        total_num = 0\n",
    "        non_flaky_num = 0\n",
    "        flaky_chaotic_order_num = 0\n",
    "        uniqueId_mutantIds_dict = {}\n",
    "        mutantId_mutantTuple_dict, mutantId_testsInOrder_dict, mutantId_runtimeList_dict = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            unique_id = tuple(mutant_tuple[:5])\n",
    "            test_list = mutantId_testsInOrder_dict[mutant_id]\n",
    "            if unique_id not in uniqueId_mutantIds_dict:\n",
    "                uniqueId_mutantIds_dict[unique_id] = set()\n",
    "            uniqueId_mutantIds_dict[unique_id].add(mutant_id)\n",
    "        total_num = len(uniqueId_mutantIds_dict)\n",
    "        for unique_id, mutant_ids in uniqueId_mutantIds_dict.items():\n",
    "            if len(mutant_ids) == 1:\n",
    "                non_flaky_num += 1\n",
    "            else:\n",
    "                test_intersection_set = None\n",
    "                for mutant_id in mutant_ids:\n",
    "                    per_test_set = set(mutantId_testsInOrder_dict[mutant_id])\n",
    "                    if test_intersection_set is None:\n",
    "                        test_intersection_set = per_test_set\n",
    "                    else:\n",
    "                        test_intersection_set &= per_test_set\n",
    "                is_same = True\n",
    "                flaky_tests = set()\n",
    "                for mutant_id in mutant_ids:\n",
    "                    per_test_set = set(mutantId_testsInOrder_dict[mutant_id])\n",
    "                    if len(per_test_set) == len(test_intersection_set):\n",
    "                        continue\n",
    "                    flaky_tests |= (per_test_set - test_intersection_set)\n",
    "                if len(flaky_tests) == 0:\n",
    "                    flaky_chaotic_order_num += 1\n",
    "                    flaky_chaotic_order_mutant_list.append(random.choice(list(mutant_ids)))\n",
    "                total_flaky_tests |= flaky_tests\n",
    "        # with open(f'analyzed_data/{choice}/mutant_list/chaotic_order/{project}_{seed}.json', 'w') as file:\n",
    "        #     json.dump(flaky_chaotic_order_mutant_list, file, indent=4)\n",
    "    \n",
    "        print(f'{project} with {seed}:')\n",
    "        print(f'Total mutants: {total_num}')\n",
    "        print(f'Non-flaky mutants: {non_flaky_num} ({non_flaky_num / total_num:.4f})')\n",
    "        print(f'Flaky mutants due to chaotic test list: {flaky_chaotic_order_num} ({flaky_chaotic_order_num / total_num:.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create guiding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict, mutant_choice, test_choice, TIMED_OUT\n",
    "random_mutant = False\n",
    "random_test = True\n",
    "choice = f'{mutant_choice[random_mutant]}_{test_choice[random_test]}'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    def test_sort(test):\n",
    "        return (test['name'])\n",
    "    \n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    if random_test:\n",
    "        random.shuffle(test_order)\n",
    "    else:\n",
    "        test_order.sort(key=test_sort)\n",
    "\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'filename': mutant[5],\n",
    "        'block': f'[{mutant[6]}]',\n",
    "        'lineNumber': int(mutant[7]),\n",
    "        'description': mutant[8],\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "\n",
    "\n",
    "parent_path = f'analyzed_data/{choice}/mutant_list'\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    # get the mutant intersection\n",
    "    id_set = set()\n",
    "    for seed in seed_list:\n",
    "        mutantId_mutantTuple_dict, _ = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        with open(f'{parent_path}/chaotic_order/{project}_{seed}.json', 'r') as file:\n",
    "            chaotic_order_list = json.load(file)\n",
    "        per_id_set = set()\n",
    "        for mutant_id in chaotic_order_list:\n",
    "            per_id_set.add(tuple(mutantId_mutantTuple_dict[mutant_id][:5]))\n",
    "        if len(id_set) == 0:\n",
    "            id_set |= per_id_set\n",
    "        else:\n",
    "            id_set &= per_id_set\n",
    "    # create guiding mutant list\n",
    "    for seed in seed_list:\n",
    "        with open(f'{parent_path}/non-flaky/{project}_{seed}.json', 'r') as file:\n",
    "            non_flaky_list = json.load(file)\n",
    "        mutantId_mutantTuple_dict, mutantId_testsInOrder_dict = get_info(f'parsed_data/{choice}/{project}_{seed}')\n",
    "        output_list = []\n",
    "        id_visited_dict = {item: True for item in id_set}\n",
    "        for mutant_id, mutant_tuple in mutantId_mutantTuple_dict.items():\n",
    "            id_tuple = tuple(mutant_tuple[:5])\n",
    "            if mutant_id in non_flaky_list or (id_tuple in id_set and id_visited_dict[id_tuple]):\n",
    "                if id_tuple in id_set:\n",
    "                    id_visited_dict[id_tuple] = False\n",
    "                output_list.append(mutant_to_json(mutant=mutant_tuple,\n",
    "                                                  test_list=mutantId_testsInOrder_dict[mutant_id],\n",
    "                                                  junit_version=junit_version))\n",
    "        if random_mutant:\n",
    "            random.shuffle(output_list)\n",
    "        else:\n",
    "            output_list.sort(key=mutant_sort)\n",
    "        with open(f'analyzed_data/{choice}/guiding_files/{project}_{seed}.json', 'w') as f:\n",
    "            f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choose fastest test order to guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "seeds = [0, 42, 123, 216, 1202, 1999, 2002, 2024, 31415, 99999]\n",
    "choice = 'more_projects'\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict, mutantId_testsInOrder_dict\n",
    "    \n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "    \n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "for project in ['commons-cli']:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    mutation_runtimes_dict = {}\n",
    "    mutation_tests_dict = {}\n",
    "    is_recorded = False\n",
    "    for seed in seeds:\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_list = json.load(f)\n",
    "        id_tuple_dict, id_runtimes_dict, id_tests_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        for mut_id in non_flaky_list:\n",
    "            mut = tuple(id_tuple_dict[mut_id])\n",
    "            runtime_list = id_runtimes_dict[mut_id]\n",
    "            runtime = round(np.mean(runtime_list))\n",
    "            if is_recorded:\n",
    "                mutation_runtimes_dict[mut].append(runtime)\n",
    "                mutation_tests_dict[mut].append(id_tests_dict[mut_id])\n",
    "            else:\n",
    "                mutation_runtimes_dict[mut] = [runtime]\n",
    "                mutation_tests_dict[mut] = [id_tests_dict[mut_id]]\n",
    "        is_recorded = True\n",
    "    output_list = []\n",
    "    for mut, runtimes in mutation_runtimes_dict.items():\n",
    "        tests = mutation_tests_dict[mut]\n",
    "        mini = 1000000\n",
    "        mini_index = -1\n",
    "        for i in range(len(seeds)):\n",
    "            if runtimes[i] < mini:\n",
    "                mini = runtimes[i]\n",
    "                mini_index = i\n",
    "        output_list.append(mutant_to_json(mutant=mut,\n",
    "                                          test_list=tests[mini_index],\n",
    "                                          junit_version=junit_version))\n",
    "    output_list.sort(key=mutant_sort)\n",
    "    with open(f'{analyzed_path}/{choice}/guiding_files/{project}_fastest.json', 'w') as f:\n",
    "        f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate input files based on single default result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from pitest_log_parser import project_junitVersion_dict\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_testsInOrder.json', 'r') as file:\n",
    "        mutantId_testsInOrder_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_testsInOrder_dict\n",
    "\n",
    "\n",
    "def mutant_to_json(mutant, test_list, junit_version):\n",
    "    test_order = []\n",
    "    if junit_version == 'junit4':\n",
    "        for test in test_list:\n",
    "            paren_index = test.find('(')\n",
    "            for i in range(paren_index, 0, -1):\n",
    "                if test[i] == '.': break\n",
    "            test_order.append({\n",
    "                'definingClass': test[:i],\n",
    "                'name': test\n",
    "            })\n",
    "    else:\n",
    "        for test in test_list:\n",
    "            class_end_index = test.find('[')\n",
    "            test_order.append({\n",
    "                'definingClass': test[:class_end_index-1],\n",
    "                'name': test\n",
    "            })\n",
    "    # random.shuffle(test_order)\n",
    "    return {\n",
    "        'id': {\n",
    "            'location': {\n",
    "                'clazz': mutant[0],\n",
    "                'method': mutant[1],\n",
    "                'methodDesc': mutant[2]\n",
    "            },\n",
    "            'indexes': f'[{mutant[3]}]',\n",
    "            'mutator': mutant[4]\n",
    "        },\n",
    "        'filename': mutant[5],\n",
    "        'block': f'[{mutant[6]}]',\n",
    "        'lineNumber': int(mutant[7]),\n",
    "        'description': mutant[8],\n",
    "        'testsInOrder': test_order\n",
    "    }\n",
    "\n",
    "\n",
    "def mutant_sort(mutant):\n",
    "    return (\n",
    "        mutant['id']['location']['clazz'],\n",
    "        mutant['id']['location']['method'],\n",
    "        mutant['id']['location']['methodDesc'],\n",
    "        mutant['id']['indexes'],\n",
    "        mutant['id']['mutator']\n",
    "    )\n",
    "\n",
    "\n",
    "for project in project_list:\n",
    "    junit_version = project_junitVersion_dict[project]\n",
    "    id_tuple_dict, id_tests_dict = get_info(f'parsed_data/default_version/{project}')\n",
    "    for seed in seed_list:\n",
    "        # random.seed(seed)\n",
    "        seed = 'default'\n",
    "        output_list = []\n",
    "        for mut_id, mut_tup in id_tuple_dict.items():\n",
    "            output_list.append(mutant_to_json(mutant=mut_tup,\n",
    "                                              test_list=id_tests_dict[mut_id],\n",
    "                                              junit_version=junit_version))\n",
    "        output_list.sort(key=mutant_sort)\n",
    "        with open(f'analyzed_data/default_version/guiding_files/{project}_{seed}.json', 'w') as f:\n",
    "            f.write(json.dumps(output_list, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze the order of mutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each clazz (each process):\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from flakiness_filter import clazz_index\n",
    "\n",
    "\n",
    "choice = 'more_projects'\n",
    "print('For each clazz (each process):')\n",
    "for project in project_list:\n",
    "    clazz_orders_dict = dict()\n",
    "    for seed in seed_list:\n",
    "        cur_clazz_orders_dict = dict()\n",
    "        with open(f'{parsed_path}/{choice}/{project}_{seed}/mutantId_mutantTuple.json', 'r') as f:\n",
    "            id_tuple_dict = json.load(f)\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_id_list = json.load(f)\n",
    "\n",
    "        for mut_id in non_flaky_id_list:\n",
    "                mut_tup = id_tuple_dict[mut_id]\n",
    "                clazz = mut_tup[clazz_index]\n",
    "                if clazz in cur_clazz_orders_dict:\n",
    "                    cur_clazz_orders_dict[clazz].append(mut_tup)\n",
    "                else:\n",
    "                    cur_clazz_orders_dict[clazz] = [mut_tup]\n",
    "        diff_cnt = 0\n",
    "        if len(clazz_orders_dict) == 0:\n",
    "            clazz_orders_dict = cur_clazz_orders_dict\n",
    "        else:\n",
    "            for clazz, mutant_order in clazz_orders_dict.items():\n",
    "                if mutant_order != cur_clazz_orders_dict[clazz]:\n",
    "                    diff_cnt += 1\n",
    "        if diff_cnt > 0:\n",
    "            print(f'The diff cnt of {project} with {seed}: {diff_cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Average runtime (per mutant) table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_info(file_path):\n",
    "    with open(f'{file_path}/mutantId_mutantTuple.json', 'r') as file:\n",
    "        mutantId_mutantTuple_dict = json.load(file)\n",
    "    with open(f'{file_path}/mutantId_runtimeList.json', 'r') as file:\n",
    "        mutantId_runtimeList_dict = json.load(file)\n",
    "    return mutantId_mutantTuple_dict, mutantId_runtimeList_dict\n",
    "\n",
    "\n",
    "choice = 'more_projects'\n",
    "cols = ['clazz', 'method', 'methodDesc', 'indexes', 'mutator'] + [f'{s}' for s in seed_list]\n",
    "for project in project_list:\n",
    "    df = pd.DataFrame(None, columns=cols)\n",
    "    mutant_runtimes_dict = dict()\n",
    "    is_recorded = False\n",
    "    for seed in seed_list:\n",
    "        id_tuple_dict, id_runtimes_dict = get_info(f'{parsed_path}/{choice}/{project}_{seed}')\n",
    "        with open(f'{analyzed_path}/{choice}/mutant_list/non-flaky/{project}_{seed}.json', 'r') as f:\n",
    "            non_flaky_id_list = json.load(f)\n",
    "        for mut_id in non_flaky_id_list:\n",
    "            mut_tup = tuple(id_tuple_dict[mut_id])\n",
    "            avg_runtime = round(np.mean(id_runtimes_dict[mut_id]))\n",
    "            if is_recorded:\n",
    "                mutant_runtimes_dict[mut_tup].append(avg_runtime)\n",
    "            else:\n",
    "                mutant_runtimes_dict[mut_tup] = [avg_runtime]\n",
    "        is_recorded = True\n",
    "    for mut, avg_runtimes in mutant_runtimes_dict.items():\n",
    "        df.loc[len(df.index)] = list(mut) + avg_runtimes\n",
    "    df.to_csv(f'{analyzed_path}/{choice}/runtime_per_mutant/{project}.csv', sep=',', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
